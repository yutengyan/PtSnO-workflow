#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step4: è®¡ç®—é›†æˆå¹³å‡æ‰©æ•£ç³»æ•°D
==========================================

åŠŸèƒ½:
1. ç›´æ¥ä»GMX MSDåŸå§‹æ•°æ®æ„å»ºæ–‡ä»¶ç´¢å¼•
2. å¯¹æ¯ä¸ª(composition, temperature, element)ç»„åˆè®¡ç®—é›†æˆå¹³å‡MSD
3. æ‹Ÿåˆé›†æˆå¹³å‡MSDæ›²çº¿å¾—åˆ°æ‰©æ•£ç³»æ•°D
4. æ”¯æŒç³»ç»Ÿè¿‡æ»¤ (ä¸step3ä¸€è‡´çš„é…ç½®)
5. æ”¯æŒå¼‚å¸¸å€¼ç­›é€‰ (å¯é€‰)
6. ç”Ÿæˆè¯¦ç»†çš„Då€¼ç»Ÿè®¡æŠ¥å‘Šå’Œå¯è§†åŒ–

æ³¨æ„:
- æœ¬è„šæœ¬ç‹¬ç«‹è¿è¡Œï¼Œä¸ä¾èµ–step2æˆ–step3çš„è¾“å‡º
- ç›´æ¥è¯»å–.xvgæ–‡ä»¶ï¼Œè®¡ç®—é›†æˆå¹³å‡ï¼Œç„¶åæ‹ŸåˆDå€¼
- ä¸step2çš„åŒºåˆ«: step2æ˜¯é¢„å…ˆè®¡ç®—å¹¶ä¿å­˜é›†æˆç»“æœï¼Œstep4æ˜¯å®æ—¶è®¡ç®—

è¾“å…¥:
- GMX MSDåŸå§‹æ•°æ® (.xvgæ–‡ä»¶ï¼Œä»GMX_DATA_DIRSè¯»å–)
- step1çš„å¼‚å¸¸æ¸…å• (large_D_outliers.csvï¼Œå¯é€‰)

è¾“å‡º:
- ensemble_D_values.csv: Då€¼æ±‡æ€»è¡¨
- D_vs_T_*.png: D-Tå…³ç³»å›¾
- D_calculation_report.txt: ç»Ÿè®¡æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
--------
python step4_calculate_ensemble_D.py              # é»˜è®¤ï¼šå¯ç”¨å¼‚å¸¸å€¼ç­›é€‰
python step4_calculate_ensemble_D.py --nofilter   # å…³é—­ç­›é€‰ï¼Œä½¿ç”¨æ‰€æœ‰æ›²çº¿
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
import re
import warnings
from collections import defaultdict
from scipy import stats
import argparse
from tqdm import tqdm
warnings.filterwarnings('ignore')

# ===== å…¨å±€é…ç½® =====
BASE_DIR = Path(__file__).parent  # workflowç›®å½•
OUTLIERS_CSV = BASE_DIR / 'results' / 'large_D_outliers.csv'

GMX_DATA_DIRS = [
    # BASE_DIR / 'data' / 'gmx_msd' / 'collected_gmx_msd',
    # BASE_DIR / 'data' / 'gmx_msd' / 'gmx_msd_results_20251015_184626_collected',
    # æ–°ç‰ˆunwrap per-atom MSDæ•°æ® (2025-11-18)
    # BASE_DIR / 'data' / 'gmx_msd' / 'unwrap' / 'gmx_msd_results_20251118_152614',
    BASE_DIR / 'data' / 'gmx_msd' / 'unwrap' / 'air' / 'gmx_msd_results_20251124_170114'  # ğŸŒ¬ï¸ æ°”è±¡æ•°æ®
]

OUTPUT_DIR = BASE_DIR / 'results' / 'ensemble_D_analysis'
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

# ===== ç³»ç»Ÿè¿‡æ»¤é…ç½® (ä¸step3ä¿æŒä¸€è‡´) =====
SYSTEM_FILTER = {
    'include_patterns': [
        # ç¤ºä¾‹: åªå¤„ç†Pt8ç›¸å…³ç³»ç»Ÿ
        # r'^pt8',           # pt8å¼€å¤´çš„æ‰€æœ‰ç³»ç»Ÿ
        # r'pt8sn\d+',       # pt8sn0, pt8sn1, ..., pt8sn10
        # r'pt\d+sn\d+',     # æ‰€æœ‰ptXsnYæ ¼å¼
        r'^\d+$',          # ğŸŒ¬ï¸ æ°”è±¡æ•°æ® (çº¯æ•°å­—å‘½åï¼Œå¦‚ 68, 86)
    ],
    'exclude_patterns': [
        # ç¤ºä¾‹: æ’é™¤å«æ°§ç³»ç»Ÿ
        # r'^[Oo]\d+',       # O1, O2, o3, o4ç­‰å¼€å¤´
        # r'[Oo]\d+Pt',      # O2Pt4Sn6ç­‰
        # r'Pt\d+Sn\d+O',    # Pt2Sn2O1ç­‰
    ]
}

# ===== æ‹Ÿåˆå‚æ•° =====
FIT_CONFIG = {
    'fit_range': (50.0, 500.0),  # æ‹Ÿåˆæ—¶é—´èŒƒå›´ (ps)
    'min_points': 10,             # æœ€å°æ•°æ®ç‚¹æ•°
    'r2_threshold': 0.95,         # RÂ²é˜ˆå€¼ (ä½äºæ­¤å€¼ä¼šæ ‡è®°)
}

COLORS = {
    'Pt': '#E74C3C',
    'Sn': '#3498DB',
    'PtSn': '#2ECC71'
}

plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def load_large_D_outliers(enable_filtering=True):
    """
    åŠ è½½å¤§Då€¼å¼‚å¸¸runæ¸…å•
    
    Parameters:
    -----------
    enable_filtering : bool
        æ˜¯å¦å¯ç”¨å¼‚å¸¸å€¼ç­›é€‰
    """
    if not enable_filtering:
        print(f"   [!] Outlier filtering is DISABLED (--nofilter)")
        print(f"   [!] Will use ALL runs (including outliers)")
        return set()
    
    try:
        df_outliers = pd.read_csv(OUTLIERS_CSV)
        outlier_files = set(df_outliers['filepath'].values)
        print(f"   [OK] Loaded outlier list: {len(outlier_files)} files")
        return outlier_files
    except FileNotFoundError:
        print(f"   [!] Outlier file not found, will use all runs")
        return set()


def build_file_index(outlier_files=None):
    """
    æ„å»ºæ–‡ä»¶ç´¢å¼• - åªç´¢å¼•æœ‰æ•ˆruns (æ’é™¤å¼‚å¸¸runs)
    
    Returns:
    --------
    file_index : dict
        {(composition, temperature, element): [file_path1, file_path2, ...]}
    """
    if outlier_files is None:
        outlier_files = set()
    
    print("\n[*] Building file index (valid runs only)...")
    file_index = defaultdict(list)
    
    total_files = 0
    filtered_files = 0
    seen_files = set()  # ç”¨äºå»é‡
    
    for gmx_dir in GMX_DATA_DIRS:
        print(f"  Scanning: {gmx_dir.name}...")
        
        for xvg_file in gmx_dir.rglob("*_msd_*.xvg"):
            # å»é‡æ£€æŸ¥
            try:
                normalized_path = xvg_file.resolve()
                if normalized_path in seen_files:
                    continue  # è·³è¿‡é‡å¤æ–‡ä»¶
                seen_files.add(normalized_path)
            except:
                pass  # å¦‚æœresolve()å¤±è´¥,ç»§ç»­å¤„ç†
            try:
                parts = xvg_file.parts
                
                # æå–element
                filename = xvg_file.stem
                if '_msd_' in filename:
                    element = filename.split('_msd_')[-1]
                else:
                    continue
                
                # æå–temperatureå’Œcomposition
                temperature = None
                composition = None
                for i in range(len(parts)-1, 0, -1):
                    if parts[i].endswith('K'):
                        temperature = parts[i]
                        composition = parts[i-1]
                        break
                
                if not temperature or not composition:
                    continue
                
                total_files += 1
                
                # åªä¿ç•™æœ‰æ•ˆruns
                if str(xvg_file) not in outlier_files:
                    key = (composition, temperature, element)
                    file_index[key].append(xvg_file)
                else:
                    filtered_files += 1
                
            except Exception as e:
                continue
    
    print(f"   [OK] Indexed {total_files - filtered_files} valid files")
    print(f"   [OK] Filtered out {filtered_files} outlier runs")
    
    return file_index


def read_gmx_msd_xvg(filepath):
    """è¯»å–GMX MSD .xvgæ–‡ä»¶"""
    time_data = []
    msd_data = []
    
    try:
        with open(filepath, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#') or line.startswith('@'):
                    continue
                parts = line.split()
                if len(parts) >= 2:
                    try:
                        t = float(parts[0])
                        msd_nm2 = float(parts[1])
                        msd_a2 = msd_nm2 * 100
                        time_data.append(t)
                        msd_data.append(msd_a2)
                    except ValueError:
                        continue
    except:
        return None, None
    
    if len(time_data) == 0:
        return None, None
    
    return np.array(time_data), np.array(msd_data)


def ensemble_average_msd(file_list):
    """
    è®¡ç®—é›†åˆå¹³å‡MSD
    
    Parameters:
    -----------
    file_list : list
        æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    
    Returns:
    --------
    time_common : ndarray
        å…¬å…±æ—¶é—´è½´
    msd_mean : ndarray
        é›†åˆå¹³å‡MSD
    msd_std : ndarray
        æ ‡å‡†å·®
    n_runs : int
        æœ‰æ•ˆrunæ•°
    """
    if not file_list:
        return None, None, None, 0
    
    # è¯»å–æ‰€æœ‰MSDæ•°æ®
    msd_list = []
    time_list = []
    
    for filepath in file_list:
        time, msd = read_gmx_msd_xvg(filepath)
        if time is not None:
            time_list.append(time)
            msd_list.append(msd)
    
    if not msd_list:
        return None, None, None, 0
    
    # å¯¹é½æ—¶é—´è½´
    min_time = max(t.min() for t in time_list)
    max_time = min(t.max() for t in time_list)
    time_common = np.linspace(min_time, max_time, 500)
    
    # æ’å€¼
    msd_interp_list = []
    for time, msd in zip(time_list, msd_list):
        try:
            msd_interp = np.interp(time_common, time, msd)
            msd_interp_list.append(msd_interp)
        except:
            continue
    
    if not msd_interp_list:
        return None, None, None, 0
    
    # è®¡ç®—ç»Ÿè®¡é‡
    msd_array = np.array(msd_interp_list)
    msd_mean = np.mean(msd_array, axis=0)
    msd_std = np.std(msd_array, axis=0, ddof=1) if len(msd_interp_list) > 1 else np.zeros_like(msd_mean)
    
    return time_common, msd_mean, msd_std, len(msd_interp_list)


def fit_msd_to_diffusion(time, msd, fit_range=None):
    """
    æ‹ŸåˆMSDåˆ°æ‰©æ•£æ–¹ç¨‹: MSD = 6Dt + b
    
    Parameters:
    -----------
    time : ndarray
        æ—¶é—´ (ps)
    msd : ndarray
        MSD (A^2)
    fit_range : tuple, optional
        æ‹Ÿåˆæ—¶é—´èŒƒå›´ (t_min, t_max) in ps
    
    Returns:
    --------
    D : float
        æ‰©æ•£ç³»æ•° (cm^2/s)
    r2 : float
        æ‹Ÿåˆä¼˜åº¦
    intercept : float
        æˆªè· (A^2)
    fit_info : dict
        æ‹Ÿåˆè¯¦ç»†ä¿¡æ¯
    """
    if fit_range is None:
        fit_range = FIT_CONFIG['fit_range']
    
    # é€‰æ‹©æ‹ŸåˆèŒƒå›´
    mask = (time >= fit_range[0]) & (time <= fit_range[1])
    
    if np.sum(mask) < FIT_CONFIG['min_points']:
        return np.nan, np.nan, np.nan, {'error': 'insufficient_points'}
    
    t_fit = time[mask]
    msd_fit = msd[mask]
    
    # çº¿æ€§æ‹Ÿåˆ
    try:
        slope, intercept, r_value, p_value, std_err = stats.linregress(t_fit, msd_fit)
        
        # è½¬æ¢å•ä½: MSD [A^2] = 6D [cm^2/s] * t [ps] * 10^-4
        # slope [A^2/ps] = 6D * 10^-4
        # D = slope / 6.0 * 1e-4 [cm^2/s]
        D = slope / 6.0 * 1e-4
        
        r2 = r_value ** 2
        
        fit_info = {
            'slope': slope,
            'intercept': intercept,
            'r2': r2,
            'p_value': p_value,
            'std_err': std_err,
            'n_points': len(t_fit),
            'fit_range': fit_range
        }
        
        return D, r2, intercept, fit_info
        
    except Exception as e:
        return np.nan, np.nan, np.nan, {'error': str(e)}


def extract_base_system(composition_name):
    """æå–åŸºç¡€ä½“ç³»åç§°"""
    match = re.match(r'^(Cv)-\d+$', composition_name)
    if match:
        return match.group(1)
    return composition_name


def filter_systems(compositions, include_patterns=None, exclude_patterns=None):
    """
    æ ¹æ®æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼è¿‡æ»¤ç³»ç»Ÿ
    
    Parameters:
    -----------
    compositions : list
        ç»„æˆåˆ—è¡¨
    include_patterns : list of str
        åŒ…å«æ¨¡å¼åˆ—è¡¨
    exclude_patterns : list of str
        æ’é™¤æ¨¡å¼åˆ—è¡¨
    
    Returns:
    --------
    filtered_comps : list
        è¿‡æ»¤åçš„ç»„æˆåˆ—è¡¨
    """
    if include_patterns is None:
        include_patterns = []
    if exclude_patterns is None:
        exclude_patterns = []
    
    filtered_comps = []
    
    for comp in compositions:
        base_sys = extract_base_system(comp)
        
        # æ£€æŸ¥include
        if include_patterns:
            included = any(re.search(pattern, base_sys, re.IGNORECASE) 
                          for pattern in include_patterns)
            if not included:
                continue
        
        # æ£€æŸ¥exclude
        if exclude_patterns:
            excluded = any(re.search(pattern, base_sys, re.IGNORECASE) 
                          for pattern in exclude_patterns)
            if excluded:
                continue
        
        filtered_comps.append(comp)
    
    return filtered_comps


def calculate_ensemble_D_values(file_index, compositions):
    """
    è®¡ç®—æ‰€æœ‰(composition, temperature, element)ç»„åˆçš„é›†åˆå¹³å‡Då€¼
    
    Parameters:
    -----------
    file_index : dict
        æ–‡ä»¶ç´¢å¼•
    compositions : list
        è¦å¤„ç†çš„ç»„æˆåˆ—è¡¨
    
    Returns:
    --------
    results : list of dict
        ç»“æœåˆ—è¡¨
    """
    results = []
    
    # è·å–æ‰€æœ‰å”¯ä¸€çš„keys
    keys = [k for k in file_index.keys() if k[0] in compositions]
    
    print(f"\n[*] Calculating ensemble D values for {len(keys)} groups...")
    
    for comp, temp, element in tqdm(keys, desc="Processing"):
        file_list = file_index[(comp, temp, element)]
        
        # è®¡ç®—é›†åˆå¹³å‡MSD
        time, msd_mean, msd_std, n_runs = ensemble_average_msd(file_list)
        
        if time is None or n_runs == 0:
            continue
        
        # æ‹ŸåˆDå€¼
        D, r2, intercept, fit_info = fit_msd_to_diffusion(time, msd_mean)
        
        # ä¿å­˜ç»“æœ
        result = {
            'composition': comp,
            'base_system': extract_base_system(comp),
            'temperature': temp,
            'temp_K': int(temp.replace('K', '')),
            'element': element,
            'D_cm2_s': D,
            'r2': r2,
            'intercept_A2': intercept,
            'n_runs': n_runs,
            'slope': fit_info.get('slope', np.nan),
            'p_value': fit_info.get('p_value', np.nan),
            'std_err': fit_info.get('std_err', np.nan),
            'n_fit_points': fit_info.get('n_points', 0),
            'fit_range_ps': f"{FIT_CONFIG['fit_range'][0]}-{FIT_CONFIG['fit_range'][1]}"
        }
        
        results.append(result)
    
    return results


def plot_D_vs_temperature(df_results, output_dir):
    """
    ç»˜åˆ¶D-Tå…³ç³»å›¾ (æŒ‰ä½“ç³»åˆ†ç»„)
    
    Parameters:
    -----------
    df_results : DataFrame
        ç»“æœæ•°æ®
    output_dir : Path
        è¾“å‡ºç›®å½•
    """
    print("\n[*] Plotting D vs Temperature...")
    
    # æŒ‰base_systemåˆ†ç»„
    systems = df_results['base_system'].unique()
    
    for base_sys in tqdm(systems, desc="Plotting"):
        df_sys = df_results[df_results['base_system'] == base_sys]
        
        if len(df_sys) == 0:
            continue
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        
        for idx, element in enumerate(['Pt', 'Sn', 'PtSn']):
            ax = axes[idx]
            
            df_elem = df_sys[df_sys['element'] == element]
            
            if len(df_elem) == 0:
                ax.text(0.5, 0.5, 'No Data', ha='center', va='center',
                       transform=ax.transAxes, fontsize=14)
                ax.set_title(f'{element}', fontsize=12, fontweight='bold')
                continue
            
            # æŒ‰compositionåˆ†ç»„ç»˜åˆ¶
            for comp in df_elem['composition'].unique():
                df_comp = df_elem[df_elem['composition'] == comp]
                df_comp = df_comp.sort_values('temp_K')
                
                # ç»˜åˆ¶Då€¼
                ax.plot(df_comp['temp_K'], df_comp['D_cm2_s'], 
                       'o-', label=comp, alpha=0.7, markersize=6)
            
            ax.set_xlabel('Temperature (K)', fontsize=11, fontweight='bold')
            ax.set_ylabel('D (cmÂ²/s)', fontsize=11, fontweight='bold')
            ax.set_title(f'{element}', fontsize=12, fontweight='bold', color=COLORS[element])
            ax.legend(fontsize=8)
            ax.grid(True, alpha=0.3)
            ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))
        
        plt.suptitle(f'{base_sys} - Diffusion Coefficient vs Temperature\n'
                    f'Ensemble Average (Valid Runs Only)',
                    fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        output_file = output_dir / f'D_vs_T_{base_sys}.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close(fig)
    
    print(f"  [OK] Generated {len(systems)} D-T plots")


def generate_report(df_results, output_dir):
    """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
    report_file = output_dir / 'D_calculation_report.txt'
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("Step4: Ensemble Average Diffusion Coefficient Calculation Report\n")
        f.write("="*80 + "\n")
        f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("="*80 + "\n\n")
        
        # æ‹Ÿåˆå‚æ•°
        f.write("Fitting Configuration:\n")
        f.write(f"  Fit range: {FIT_CONFIG['fit_range'][0]}-{FIT_CONFIG['fit_range'][1]} ps\n")
        f.write(f"  Min points: {FIT_CONFIG['min_points']}\n")
        f.write(f"  RÂ² threshold: {FIT_CONFIG['r2_threshold']}\n\n")
        
        # æ€»ä½“ç»Ÿè®¡
        f.write("Overall Statistics:\n")
        f.write(f"  Total groups: {len(df_results)}\n")
        f.write(f"  Systems: {df_results['base_system'].nunique()}\n")
        f.write(f"  Compositions: {df_results['composition'].nunique()}\n")
        f.write(f"  Temperatures: {df_results['temperature'].nunique()}\n")
        f.write(f"  Elements: {', '.join(df_results['element'].unique())}\n\n")
        
        # RÂ²ç»Ÿè®¡
        low_r2 = df_results[df_results['r2'] < FIT_CONFIG['r2_threshold']]
        f.write(f"Fit Quality:\n")
        f.write(f"  RÂ² â‰¥ {FIT_CONFIG['r2_threshold']}: {len(df_results) - len(low_r2)} groups ({(len(df_results)-len(low_r2))/len(df_results)*100:.1f}%)\n")
        f.write(f"  RÂ² < {FIT_CONFIG['r2_threshold']}: {len(low_r2)} groups ({len(low_r2)/len(df_results)*100:.1f}%)\n")
        if len(low_r2) > 0:
            f.write(f"  Mean RÂ² (low quality): {low_r2['r2'].mean():.4f}\n")
        f.write(f"  Mean RÂ² (all): {df_results['r2'].mean():.4f}\n\n")
        
        # Då€¼èŒƒå›´
        f.write("D Value Range:\n")
        for element in ['Pt', 'Sn', 'PtSn']:
            df_elem = df_results[df_results['element'] == element]
            if len(df_elem) > 0:
                f.write(f"  {element}:\n")
                f.write(f"    Min: {df_elem['D_cm2_s'].min():.2e} cmÂ²/s\n")
                f.write(f"    Max: {df_elem['D_cm2_s'].max():.2e} cmÂ²/s\n")
                f.write(f"    Mean: {df_elem['D_cm2_s'].mean():.2e} cmÂ²/s\n")
                f.write(f"    Median: {df_elem['D_cm2_s'].median():.2e} cmÂ²/s\n")
        
        f.write("\n" + "="*80 + "\n")
        f.write("Detailed Results saved to: ensemble_D_values.csv\n")
        f.write("="*80 + "\n")
    
    print(f"  [OK] Saved: {report_file.name}")


def main(enable_filtering=True):
    """
    ä¸»å‡½æ•°
    
    Parameters:
    -----------
    enable_filtering : bool
        æ˜¯å¦å¯ç”¨å¼‚å¸¸å€¼ç­›é€‰
    """
    print("\n" + "="*80)
    print("Step4: Calculate Ensemble Average Diffusion Coefficients")
    print("="*80)
    print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    # 1. åŠ è½½å¼‚å¸¸æ¸…å•
    print("\n[1/5] Loading outlier list...")
    outlier_files = load_large_D_outliers(enable_filtering)
    
    # 2. æ„å»ºæ–‡ä»¶ç´¢å¼•
    file_index = build_file_index(outlier_files)
    
    # 3. è·å–æ‰€æœ‰ç»„æˆå¹¶åº”ç”¨è¿‡æ»¤
    all_compositions = set(k[0] for k in file_index.keys())
    print(f"\n[2/5] Total compositions: {len(all_compositions)}")
    
    include_patterns = SYSTEM_FILTER.get('include_patterns', [])
    exclude_patterns = SYSTEM_FILTER.get('exclude_patterns', [])
    
    if include_patterns or exclude_patterns:
        print(f"\n[*] Applying system filters...")
        if include_patterns:
            print(f"    Include patterns: {include_patterns}")
        if exclude_patterns:
            print(f"    Exclude patterns: {exclude_patterns}")
        
        compositions = filter_systems(list(all_compositions), include_patterns, exclude_patterns)
        print(f"    Filtered: {len(compositions)} compositions selected")
    else:
        compositions = list(all_compositions)
    
    systems = set(extract_base_system(c) for c in compositions)
    print(f"    Systems to process: {len(systems)}")
    
    # 4. è®¡ç®—é›†åˆå¹³å‡Då€¼
    print(f"\n[3/5] Calculating ensemble D values...")
    results = calculate_ensemble_D_values(file_index, compositions)
    
    if not results:
        print("[X] No results generated!")
        return
    
    # 5. ä¿å­˜ç»“æœ
    print(f"\n[4/5] Saving results...")
    df_results = pd.DataFrame(results)
    
    # æŒ‰ä½“ç³»ã€æ¸©åº¦ã€å…ƒç´ æ’åº
    df_results = df_results.sort_values(['base_system', 'temp_K', 'element'])
    
    output_csv = OUTPUT_DIR / 'ensemble_D_values.csv'
    df_results.to_csv(output_csv, index=False, float_format='%.6e')
    print(f"  [OK] Saved: {output_csv}")
    print(f"       Total groups: {len(df_results)}")
    
    # 6. ç”Ÿæˆå¯è§†åŒ–å’ŒæŠ¥å‘Š
    print(f"\n[5/5] Generating visualizations and report...")
    plot_D_vs_temperature(df_results, OUTPUT_DIR)
    generate_report(df_results, OUTPUT_DIR)
    
    print("\n" + "="*80)
    print("DONE!")
    print("="*80)
    print(f"Output directory: {OUTPUT_DIR}")
    print(f"  - ensemble_D_values.csv: Då€¼æ±‡æ€»è¡¨ ({len(df_results)} groups)")
    print(f"  - D_vs_T_*.png: D-Tå…³ç³»å›¾ ({len(systems)} systems)")
    print(f"  - D_calculation_report.txt: ç»Ÿè®¡æŠ¥å‘Š")
    print("="*80)


if __name__ == '__main__':
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='è®¡ç®—é›†æˆå¹³å‡æ‰©æ•£ç³»æ•° (æ”¯æŒå¼‚å¸¸å€¼ç­›é€‰)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python step4_calculate_ensemble_D.py              # é»˜è®¤ï¼šåªä½¿ç”¨æœ‰æ•ˆæ›²çº¿
  python step4_calculate_ensemble_D.py --nofilter   # ä½¿ç”¨æ‰€æœ‰æ›²çº¿ï¼ˆåŒ…æ‹¬å¼‚å¸¸å€¼ï¼‰
        """
    )
    parser.add_argument(
        '--nofilter',
        action='store_true',
        help='å…³é—­å¼‚å¸¸å€¼ç­›é€‰ï¼Œä½¿ç”¨æ‰€æœ‰æ›²çº¿è®¡ç®—æ‰©æ•£ç³»æ•°'
    )
    
    args = parser.parse_args()
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°å†³å®šæ˜¯å¦ç­›é€‰
    enable_filtering = not args.nofilter
    
    main(enable_filtering)
