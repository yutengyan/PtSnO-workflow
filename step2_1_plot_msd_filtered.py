#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»˜åˆ¶ç‰¹å®šä½“ç³»çš„MSDæ›²çº¿ - ä»…300Kå’Œ900K (å¯é€‰è¿‡æ»¤)
====================================================
åˆ›å»ºæ—¶é—´: 2025-10-16
æœ€åæ›´æ–°: 2025-11-25

æ”¯æŒçš„æ•°æ®é›†:
    1. 'pt8sn6' - Pt8Sn6 è´Ÿè½½å‹æ•°æ®
       è·¯å¾„: data/gmx_msd/unwrap/gmx_msd_results_20251118_152614
       è¾“å‡º: results/msd_curves_pt8sn6_loaded/
    
    2. 'air_86' - æ°”è±¡æ•°æ® 86 ç³»ç»Ÿ
       è·¯å¾„: data/gmx_msd/unwrap/air/gmx_msd_results_20251124_170114
       è¾“å‡º: results/msd_curves_air_86/

åŠŸèƒ½:
1. æ”¯æŒå¤šä¸ªæ•°æ®é›†åˆ‡æ¢ (é€šè¿‡ DATASET é…ç½®)
2. ä»…ç»˜åˆ¶300Kå’Œ900Kä¸¤ä¸ªæ¸©åº¦
3. å¯é€‰æ‹©æ˜¯å¦è¿‡æ»¤Då€¼é”™è¯¯çš„runs (é€šè¿‡ENABLE_FILTERINGé…ç½®)
4. ç»Ÿä¸€Yè½´åæ ‡èŒƒå›´
5. ç®€æ´çš„å›¾è¡¨æ˜¾ç¤º

é…ç½®æ–¹æ³•:
---------
1. åˆ‡æ¢æ•°æ®é›†:
   ä¿®æ”¹ DATASET å˜é‡:
   DATASET = 'pt8sn6'    # ä½¿ç”¨ Pt8Sn6 è´Ÿè½½å‹æ•°æ®
   DATASET = 'air_86'    # ä½¿ç”¨æ°”è±¡æ•°æ® 86 ç³»ç»Ÿ

2. å¯ç”¨/ç¦ç”¨è¿‡æ»¤:
   ENABLE_FILTERING = True   # è¿‡æ»¤å¼‚å¸¸runs (é»˜è®¤)
   ENABLE_FILTERING = False  # ç»˜åˆ¶æ‰€æœ‰runs

ä½¿ç”¨ç¤ºä¾‹:
---------
# ç»˜åˆ¶ Pt8Sn6 æ•°æ®
DATASET = 'pt8sn6'
ENABLE_FILTERING = True
python step3_1_plot_msd_filtered.py

# ç»˜åˆ¶æ°”è±¡æ•°æ® 86 ç³»ç»Ÿ
DATASET = 'air_86'
ENABLE_FILTERING = True
python step3_1_plot_msd_filtered.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
import re  # æ·»åŠ æ­£åˆ™è¡¨è¾¾å¼æ”¯æŒ
import warnings
from collections import defaultdict
warnings.filterwarnings('ignore')

# ===== æ•°æ®é›†é€‰æ‹©é…ç½® =====
# å¯é€‰å€¼: 'pt8sn6' æˆ– 'air_86'
DATASET = 'pt8sn6'  # ğŸ”§ ä¿®æ”¹æ­¤å¤„åˆ‡æ¢æ•°æ®é›†

# æ•°æ®é›†é…ç½®å­—å…¸
DATASET_CONFIGS = {
    'pt8sn6': {
        'name': 'Pt8Sn6è´Ÿè½½å‹',
        'data_dir': 'data/gmx_msd/unwrap/gmx_msd_results_20251118_152614',
        'output_dir': 'results/msd_curves_pt8sn6_loaded',
        'system_pattern': r'^pt8sn6',
        'target_temps': ['300K', '900K'],
        'description': 'Pt8Sn6 è´Ÿè½½å‹æ•°æ® (unwrap per-atom MSD)'
    },
    'air_86': {
        'name': 'æ°”è±¡æ•°æ®86',
        'data_dir': 'data/gmx_msd/unwrap/air/gmx_msd_results_20251124_170114',
        'output_dir': 'results/msd_curves_air_86',
        'system_pattern': r'^86$',
        'target_temps': ['300K', '900K'],
        'description': 'æ°”è±¡æ•°æ® 86 ç³»ç»Ÿ (atmospheric conditions)'
    }
}

# ===== å…¨å±€é…ç½® =====
BASE_DIR = Path(__file__).parent  # workflowç›®å½•
OUTLIERS_CSV = BASE_DIR / 'results' / 'large_D_outliers.csv'

# æ ¹æ®é€‰æ‹©çš„æ•°æ®é›†è®¾ç½®é…ç½®
if DATASET not in DATASET_CONFIGS:
    raise ValueError(f"æœªçŸ¥çš„æ•°æ®é›†: {DATASET}. å¯é€‰å€¼: {list(DATASET_CONFIGS.keys())}")

current_config = DATASET_CONFIGS[DATASET]
GMX_DATA_DIRS = [BASE_DIR / current_config['data_dir']]
OUTPUT_DIR = BASE_DIR / current_config['output_dir']
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

# ===== ä¸“ç”¨é…ç½® =====
TARGET_SYSTEM_PATTERN = current_config['system_pattern']  # ç›®æ ‡ä½“ç³»åŒ¹é…æ¨¡å¼
TARGET_TEMPS = current_config['target_temps']  # ç›®æ ‡æ¸©åº¦
ENABLE_FILTERING = True  # æ˜¯å¦å¯ç”¨Då€¼è¿‡æ»¤ (True=è¿‡æ»¤å¼‚å¸¸runs, False=ç»˜åˆ¶æ‰€æœ‰runs)

COLORS = {
    'Pt': '#E74C3C',
    'Sn': '#3498DB',
    'PtSn': '#2ECC71'
}

plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def load_large_D_outliers():
    """
    åŠ è½½å¤§Då€¼å¼‚å¸¸runæ¸…å•
    
    Returns:
    --------
    outliers : set
        å¼‚å¸¸æ–‡ä»¶è·¯å¾„é›†åˆ
    """
    if not ENABLE_FILTERING:
        print(f"\n[!] è¿‡æ»¤åŠŸèƒ½å·²ç¦ç”¨ - å°†ç»˜åˆ¶æ‰€æœ‰runs")
        return set()
    
    try:
        df_outliers = pd.read_csv(OUTLIERS_CSV)
        outlier_files = set(df_outliers['filepath'].values)
        print(f"\n[âˆš] å·²åŠ è½½å¼‚å¸¸runæ¸…å•: {len(outlier_files)} ä¸ªæ–‡ä»¶")
        print(f"    è¿™äº›runså°†è¢«è‡ªåŠ¨è¿‡æ»¤æ‰")
        return outlier_files
    except FileNotFoundError:
        print(f"\n[!] æœªæ‰¾åˆ°å¼‚å¸¸æ–‡ä»¶æ¸…å•: {OUTLIERS_CSV}")
        print(f"    å°†ç»˜åˆ¶æ‰€æœ‰runs")
        return set()


def build_file_index_for_target(outlier_files=None):
    """
    æ„å»ºç›®æ ‡ä½“ç³»çš„æ–‡ä»¶ç´¢å¼• (å¸¦è”åŠ¨è¿‡æ»¤)
    
    Parameters:
    -----------
    outlier_files : set, optional
        å¼‚å¸¸æ–‡ä»¶è·¯å¾„é›†åˆ
    
    Returns:
    --------
    file_index : dict
        {(composition, temperature, element): [file_path1, file_path2, ...]}
    stats : dict
        ç­›é€‰ç»Ÿè®¡
    compositions_found : list
        æ‰¾åˆ°çš„æ‰€æœ‰åŒ¹é…compositionåˆ—è¡¨
    
    è”åŠ¨è¿‡æ»¤é€»è¾‘:
        å¦‚æœåŒä¸€ä¸ªæ¨¡æ‹Ÿçš„ä»»ä½•å…ƒç´ è¢«æ ‡è®°ä¸ºå¼‚å¸¸ï¼Œåˆ™è¯¥æ¨¡æ‹Ÿçš„æ‰€æœ‰å…ƒç´ éƒ½è¢«è¿‡æ»¤
    """
    if outlier_files is None:
        outlier_files = set()
    
    print(f"\n[*] æ­£åœ¨ä¸ºåŒ¹é… '{TARGET_SYSTEM_PATTERN}' çš„ä½“ç³»æ„å»ºæ–‡ä»¶ç´¢å¼•...")
    print(f"    ç›®æ ‡æ¸©åº¦: {', '.join(TARGET_TEMPS)}")
    
    # ========== ç¬¬ä¸€éæ‰«æ: æ”¶é›†æ‰€æœ‰æ–‡ä»¶å¹¶è¯†åˆ«å¼‚å¸¸æ¨¡æ‹Ÿ ==========
    all_files = []  # [(xvg_file, composition, temperature, element, sim_id), ...]
    bad_simulations = set()  # æœ‰å¼‚å¸¸å…ƒç´ çš„æ¨¡æ‹ŸIDé›†åˆ
    
    for gmx_dir in GMX_DATA_DIRS:
        if not gmx_dir.exists():
            continue
            
        print(f"  æ‰«æç›®å½•: {gmx_dir.name}...")
        
        for xvg_file in gmx_dir.rglob("*_msd_*.xvg"):
            try:
                parts = xvg_file.parts
                filename = xvg_file.stem
                if '_msd_' not in filename:
                    continue
                element = filename.split('_msd_')[-1]
                
                # æå– sim_id (å¦‚ T300.r1.gpu0)
                sim_id = filename.split('_msd_')[0]  # T300.r1.gpu0
                
                temperature = None
                composition = None
                for i in range(len(parts)-1, 0, -1):
                    if parts[i].endswith('K'):
                        temperature = parts[i]
                        composition = parts[i-1]
                        break
                
                if not temperature or not composition:
                    continue
                
                if not re.match(TARGET_SYSTEM_PATTERN, composition, re.IGNORECASE):
                    continue
                if temperature not in TARGET_TEMPS:
                    continue
                
                # å®Œæ•´çš„æ¨¡æ‹Ÿæ ‡è¯† (composition + temperature + sim_id)
                full_sim_id = f"{composition}_{temperature}_{sim_id}"
                
                all_files.append((xvg_file, composition, temperature, element, full_sim_id))
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚å¸¸run - å¦‚æœæ˜¯ï¼Œæ ‡è®°æ•´ä¸ªæ¨¡æ‹Ÿ
                if str(xvg_file) in outlier_files:
                    bad_simulations.add(full_sim_id)
                    
            except Exception as e:
                continue
    
    print(f"  [INFO] è¯†åˆ«åˆ° {len(bad_simulations)} ä¸ªå¼‚å¸¸æ¨¡æ‹Ÿ (è”åŠ¨è¿‡æ»¤)")
    
    # ========== ç¬¬äºŒé: æŒ‰è”åŠ¨è§„åˆ™è¿‡æ»¤ ==========
    file_index = defaultdict(list)
    compositions_found = set()
    stats = {
        'total_found': 0,
        'kept': 0,
        'filtered': 0,
        'by_temp': {},
        'by_element': {}
    }
    
    for temp in TARGET_TEMPS:
        stats['by_temp'][temp] = {'total': 0, 'kept': 0, 'filtered': 0}
    for elem in ['Pt', 'Sn', 'PtSn']:
        stats['by_element'][elem] = {'total': 0, 'kept': 0, 'filtered': 0}
    
    for xvg_file, composition, temperature, element, full_sim_id in all_files:
        compositions_found.add(composition)
        stats['total_found'] += 1
        stats['by_temp'][temperature]['total'] += 1
        if element in stats['by_element']:
            stats['by_element'][element]['total'] += 1
        
        # è”åŠ¨è¿‡æ»¤: å¦‚æœè¯¥æ¨¡æ‹Ÿæœ‰ä»»ä½•å¼‚å¸¸å…ƒç´ ï¼Œåˆ™å…¨éƒ¨è¿‡æ»¤
        if full_sim_id in bad_simulations:
            stats['filtered'] += 1
            stats['by_temp'][temperature]['filtered'] += 1
            if element in stats['by_element']:
                stats['by_element'][element]['filtered'] += 1
        else:
            key = (composition, temperature, element)
            file_index[key].append(xvg_file)
            stats['kept'] += 1
            stats['by_temp'][temperature]['kept'] += 1
            if element in stats['by_element']:
                stats['by_element'][element]['kept'] += 1
    
    compositions_found = sorted(compositions_found)
    
    print(f"\n  [âˆš] ç´¢å¼•æ„å»ºå®Œæˆ (è”åŠ¨è¿‡æ»¤å·²å¯ç”¨):")
    print(f"      æ‰¾åˆ°çš„composition: {', '.join(compositions_found) if compositions_found else 'æ— '}")
    print(f"      æ€»æ–‡ä»¶æ•°: {stats['total_found']}")
    print(f"      ä¿ç•™: {stats['kept']} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
    print(f"      è¿‡æ»¤: {stats['filtered']} ä¸ªå¼‚å¸¸æ–‡ä»¶ (è”åŠ¨)")
    
    for temp in TARGET_TEMPS:
        temp_stats = stats['by_temp'][temp]
        print(f"      {temp}: {temp_stats['kept']}/{temp_stats['total']} ä¸ªæœ‰æ•ˆæ–‡ä»¶ "
              f"(è¿‡æ»¤ {temp_stats['filtered']} ä¸ª)")
    
    # æŒ‰å…ƒç´ ç»Ÿè®¡ (éªŒè¯è”åŠ¨ä¸€è‡´æ€§)
    print(f"      æŒ‰å…ƒç´ ç»Ÿè®¡:")
    for elem in ['Pt', 'Sn', 'PtSn']:
        elem_stats = stats['by_element'].get(elem, {'kept': 0, 'total': 0})
        print(f"        {elem}: {elem_stats['kept']}/{elem_stats['total']} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
    
    return file_index, stats, compositions_found


def read_gmx_msd_xvg(filepath):
    """è¯»å–GMX MSD .xvgæ–‡ä»¶"""
    time_data = []
    msd_data = []
    
    try:
        with open(filepath, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#') or line.startswith('@'):
                    continue
                parts = line.split()
                if len(parts) >= 2:
                    try:
                        t = float(parts[0])
                        msd_nm2 = float(parts[1])
                        msd_a2 = msd_nm2 * 100  # nm^2 -> A^2
                        time_data.append(t)
                        msd_data.append(msd_a2)
                    except ValueError:
                        continue
    except:
        return None, None
    
    if len(time_data) == 0:
        return None, None
    
    return np.array(time_data), np.array(msd_data)


def plot_pt8sn6_300k_900k(file_index, stats, compositions_found):
    """
    ç»˜åˆ¶Pt8Sn6çš„300Kå’Œ900K MSDæ›²çº¿
    
    Parameters:
    -----------
    file_index : dict
        æ–‡ä»¶ç´¢å¼•
    stats : dict
        ç»Ÿè®¡ä¿¡æ¯
    compositions_found : list
        æ‰¾åˆ°çš„compositionåˆ—è¡¨
    """
    comp_str = ', '.join(compositions_found) if len(compositions_found) > 1 else compositions_found[0]
    print(f"\n{'='*80}")
    print(f"ç»˜åˆ¶: {comp_str} - 300K & 900K (è¿‡æ»¤ç‰ˆ)")
    print(f"{'='*80}")
    
    # åˆ›å»º2åˆ—å¸ƒå±€ (300K | 900K)
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    # ç¬¬1æ­¥: åŠ è½½æ‰€æœ‰æ•°æ®å¹¶æ‰¾å…¨å±€æœ€å¤§MSDå€¼
    print("\n[*] åŠ è½½MSDæ•°æ®...")
    
    msd_cache = {}  # {(temp, element): [(time, msd), ...]}
    global_max_msd = 0
    
    for temp in TARGET_TEMPS:
        for element in ['Pt', 'Sn', 'PtSn']:
            msd_list = []
            
            # éå†æ‰€æœ‰æ‰¾åˆ°çš„composition
            for comp in compositions_found:
                key = (comp, temp, element)
                files = file_index.get(key, [])
                
                for filepath in files:
                    time, msd = read_gmx_msd_xvg(filepath)
                    if time is not None:
                        msd_list.append((time, msd))
                        
                        # æ›´æ–°å…¨å±€æœ€å¤§å€¼
                        max_val = np.max(msd)
                        if max_val > global_max_msd:
                            global_max_msd = max_val
            
            if msd_list:
                msd_cache[(temp, element)] = msd_list
    
    total_curves = sum(len(v) for v in msd_cache.values())
    print(f"  [âˆš] å·²åŠ è½½ {total_curves} æ¡æœ‰æ•ˆMSDæ›²çº¿")
    print(f"  [âˆš] å…¨å±€æœ€å¤§MSDå€¼: {global_max_msd:.2f} Ã…Â²")
    
    # è®¾ç½®ç»Ÿä¸€çš„Yè½´ä¸Šé™ (ç•™10%ä½™é‡)
    unified_ylim = global_max_msd * 1.1
    
    # ç¬¬2æ­¥: ç»˜åˆ¶æ¯ä¸ªæ¸©åº¦
    print("\n[*] ç»˜åˆ¶ä¸­...")
    
    for idx, temp in enumerate(TARGET_TEMPS):
        ax = axes[idx]
        has_data = False
        
        temp_stats = stats['by_temp'][temp]
        
        # ç»˜åˆ¶ä¸‰ç§å…ƒç´ 
        for element in ['Pt', 'Sn', 'PtSn']:
            msd_list = msd_cache.get((temp, element), [])
            
            if not msd_list:
                continue
            
            has_data = True
            color = COLORS.get(element, '#95a5a6')
            
            # å¯¹é½æ—¶é—´è½´å¹¶ç»˜åˆ¶æ‰€æœ‰runs
            min_len = min(len(msd) for _, msd in msd_list)
            for time, msd in msd_list:
                ax.plot(time[:min_len], msd[:min_len], 
                       color=color, alpha=0.3, linewidth=1)
            
            # è®¡ç®—å¹³å‡æ›²çº¿
            msd_aligned = np.array([msd[:min_len] for _, msd in msd_list])
            time_common = msd_list[0][0][:min_len]
            msd_mean = np.mean(msd_aligned, axis=0)
            
            # ç»˜åˆ¶å¹³å‡æ›²çº¿ (ç²—çº¿)
            ax.plot(time_common, msd_mean, 
                   color=color, linewidth=3, alpha=0.9,
                   label=f'{element} (n={len(msd_list)})')
        
        if has_data:
            # ç»Ÿä¸€Yè½´èŒƒå›´
            ax.set_ylim(0, unified_ylim)
            
            ax.set_xlabel('Time (ps)', fontsize=12, fontweight='bold')
            ax.set_ylabel(r'MSD ($\AA^2$)', fontsize=12, fontweight='bold')
            
            # æ ‡é¢˜ï¼šæ ¹æ®æ˜¯å¦è¿‡æ»¤æ˜¾ç¤ºä¸åŒä¿¡æ¯
            if ENABLE_FILTERING and temp_stats['filtered'] > 0:
                title_text = (f'{comp_str} @ {temp}\n'
                             f'æœ‰æ•ˆruns: {temp_stats["kept"]}')
            else:
                title_text = f'{comp_str} @ {temp}\nRuns: {temp_stats["kept"]}'
            
            ax.set_title(title_text, fontsize=13, fontweight='bold')
            ax.legend(fontsize=10, loc='upper left', framealpha=0.9)
            ax.grid(True, alpha=0.3, linestyle=':', linewidth=1)
        else:
            ax.text(0.5, 0.5, f'æ— æ•°æ®\n{temp}',
                   ha='center', va='center',
                   fontsize=14, fontweight='bold',
                   transform=ax.transAxes)
            ax.axis('off')
    
    # æ€»æ ‡é¢˜
    if ENABLE_FILTERING and stats['filtered'] > 0:
        title_suffix = f'(è¿‡æ»¤ç‰ˆ - å·²è¿‡æ»¤{stats["filtered"]}ä¸ªå¼‚å¸¸runs)'
    else:
        title_suffix = '(æ‰€æœ‰runs)'
    
    fig.suptitle(f'{comp_str.upper()} MSDæ›²çº¿å¯¹æ¯” - 300K vs 900K {title_suffix}',
                 fontsize=15, fontweight='bold', y=0.98)
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    
    # ä¿å­˜å›¾ç‰‡
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename_base = compositions_found[0].replace('-', '_') if compositions_found else 'pt8sn6'
    filter_tag = 'filtered' if ENABLE_FILTERING else 'all'
    output_file = OUTPUT_DIR / f'{filename_base}_300K_900K_{filter_tag}_{timestamp}.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"\n[âˆš] å›¾ç‰‡å·²ä¿å­˜: {output_file}")
    
    plt.show()
    plt.close()


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print(f"MSDæ›²çº¿ç»˜åˆ¶ - {current_config['name']} - 300K & 900K")
    print("="*80)
    print(f"\næ•°æ®é›†: {DATASET}")
    print(f"  æè¿°: {current_config['description']}")
    print(f"  æ•°æ®è·¯å¾„: {current_config['data_dir']}")
    print(f"\né…ç½®:")
    print(f"  ç›®æ ‡ä½“ç³»æ¨¡å¼: {TARGET_SYSTEM_PATTERN}")
    print(f"  ç›®æ ‡æ¸©åº¦: {', '.join(TARGET_TEMPS)}")
    print(f"  Då€¼è¿‡æ»¤: {'å¯ç”¨' if ENABLE_FILTERING else 'ç¦ç”¨'}")
    print(f"  è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    
    # 1. åŠ è½½å¼‚å¸¸runæ¸…å•
    outlier_files = load_large_D_outliers()
    
    # 2. æ„å»ºæ–‡ä»¶ç´¢å¼• (ä»…ç›®æ ‡ä½“ç³»å’Œæ¸©åº¦)
    file_index, stats, compositions_found = build_file_index_for_target(outlier_files)
    
    if stats['kept'] == 0:
        print(f"\n[X] é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„MSDæ•°æ®æ–‡ä»¶!")
        print(f"    è¯·æ£€æŸ¥:")
        print(f"    1. æ•°æ®ç›®å½•æ˜¯å¦æ­£ç¡®")
        print(f"    2. åŒ¹é… '{TARGET_SYSTEM_PATTERN}' çš„ä½“ç³»æ˜¯å¦å­˜åœ¨")
        print(f"    3. 300Kå’Œ900Kæ¸©åº¦ç‚¹æ˜¯å¦å­˜åœ¨")
        return
    
    # 3. ç»˜åˆ¶
    plot_pt8sn6_300k_900k(file_index, stats, compositions_found)
    
    print("\n" + "="*80)
    print("å®Œæˆ!")
    print("="*80)


if __name__ == '__main__':
    main()
