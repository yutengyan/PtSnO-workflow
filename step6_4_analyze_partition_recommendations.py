#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†åŒºç­–ç•¥åˆ†æè„šæœ¬ v2.4
======================

åŸºäº 1åˆ†åŒº vs 2åˆ†åŒº vs 3åˆ†åŒº çš„å¯¹æ¯”åˆ†æã€‚

æ ¸å¿ƒæ€è·¯ï¼š
1. å…ˆåˆ¤æ–­"åˆ†åŒºæ˜¯å¦æœ‰æ„ä¹‰"ï¼ˆn=2 vs n=1 çš„RÂ²å¢ç›Šï¼‰
   - å¢ç›Š < 2%: æ¨èn=1ï¼Œåˆ†åŒºæ— æ„ä¹‰
2. å†æ¯”è¾ƒn=2 vs n=3ï¼ˆä»…å½“åˆ†åŒºæœ‰æ„ä¹‰æ—¶ï¼‰
   - å·®å¼‚ä¸æ˜¾è‘—æ—¶ï¼Œé€‰æ‹©ç®€å•æ¨¡å‹n=2
3. æ–°å¢ï¼šæ£€æŸ¥3åˆ†åŒºçš„çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§
   - å¦‚æœpartition2å’Œpartition3çš„çƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼ˆå·®å¼‚<2å€è¯¯å·®ï¼‰ï¼Œè¯´æ˜3åˆ†åŒºæ— æ„ä¹‰

è¯„åˆ†å…¬å¼ (0-100åˆ†ï¼Œä»…ç”¨äºn=2å’Œn=3çš„æ¯”è¾ƒ):
- RÂ² æ‹Ÿåˆä¼˜åº¦: 50% (å¹³å‡RÂ² 40% + æœ€å°RÂ² 10%)
- èšç±»è´¨é‡: 30% (Silhouette Score)
- Cvè¯¯å·®: 20% (è¯¯å·®è¶Šå°è¶Šå¥½)

æ³¨æ„ï¼š1åˆ†åŒºæ²¡æœ‰èšç±»ï¼Œåªç”¨RÂ²ä½œä¸ºåŸºå‡†åˆ¤æ–­åˆ†åŒºæ˜¯å¦æœ‰æ„ä¹‰

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025-11-28
ç‰ˆæœ¬: 2.4
"""

import pandas as pd
import numpy as np
from pathlib import Path
import re
from collections import defaultdict
from scipy import stats


def extract_structure_name(filename):
    """ä»æ–‡ä»¶åæå–ç»“æ„å"""
    match = re.match(r'(.+?)_(auto2|auto3|fixed2|fixed3|kmeans_n2|kmeans_n3)_quality_metrics\.csv', filename)
    if match:
        return match.group(1), match.group(2)
    return None, None


def load_quality_metrics(results_dir):
    """åŠ è½½æ‰€æœ‰è´¨é‡æŒ‡æ ‡æ–‡ä»¶"""
    results_dir = Path(results_dir)
    
    data = defaultdict(dict)
    
    for csv_file in results_dir.glob('*_quality_metrics.csv'):
        structure, partition_type = extract_structure_name(csv_file.name)
        if structure and partition_type:
            try:
                df = pd.read_csv(csv_file)
                if not df.empty:
                    data[structure][partition_type] = df
            except Exception as e:
                print(f"[WARNING] æ— æ³•è¯»å– {csv_file.name}: {e}")
    
    return data


def calculate_single_partition_r2(results_dir, structure):
    """è®¡ç®—1åˆ†åŒºï¼ˆæ•´ä½“çº¿æ€§æ‹Ÿåˆï¼‰çš„RÂ²
    
    ä»clustered_data.csvè¯»å–åŸå§‹æ•°æ®ï¼Œè¿›è¡Œæ•´ä½“èƒ½é‡-æ¸©åº¦çº¿æ€§æ‹Ÿåˆ
    ä¸2/3åˆ†åŒºçš„çƒ­å®¹RÂ²ä¿æŒä¸€è‡´çš„æ¯”è¾ƒåŸºå‡†
    """
    results_dir = Path(results_dir)
    
    # å°è¯•è¯»å–ä»»æ„ä¸€ä¸ªclustered_dataæ–‡ä»¶
    for pattern in [f'{structure}_kmeans_n2_clustered_data.csv', 
                    f'{structure}_auto2_clustered_data.csv']:
        data_file = results_dir / pattern
        if data_file.exists():
            try:
                df = pd.read_csv(data_file)
                # æ£€æŸ¥æ¸©åº¦å’Œèƒ½é‡åˆ—å
                temp_col = 'temperature' if 'temperature' in df.columns else 'temp'
                energy_col = 'avg_energy' if 'avg_energy' in df.columns else 'energy'
                
                if temp_col in df.columns and energy_col in df.columns:
                    # æŒ‰æ¸©åº¦å¹³å‡åæ‹Ÿåˆï¼ˆä¸2/3åˆ†åŒºä¿æŒä¸€è‡´ï¼‰
                    df_avg = df.groupby(temp_col).agg({energy_col: 'mean'}).reset_index()
                    x = df_avg[temp_col].values
                    y = df_avg[energy_col].values
                    
                    # çº¿æ€§å›å½’ (æ¸©åº¦ vs èƒ½é‡)
                    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
                    r2 = r_value ** 2
                    
                    return {
                        'r2': r2,
                        'slope': slope,  # Cv = slope * 1000 meV/K
                        'intercept': intercept,
                        'n_points': len(x)
                    }
            except Exception as e:
                print(f"[WARNING] è®¡ç®—1åˆ†åŒºRÂ²å¤±è´¥ {structure}: {e}")
    
    return None


def calculate_comprehensive_score(df):
    """è®¡ç®—ç»¼åˆè¯„åˆ† (0-100åˆ†)
    
    è¯„åˆ†å…¬å¼:
    - RÂ² æ‹Ÿåˆä¼˜åº¦: 50% (å¹³å‡RÂ² 40% + æœ€å°RÂ² 10%)
    - èšç±»è´¨é‡: 30% (Silhouette Score, èŒƒå›´[-1,1])
    - Cvè¯¯å·®: 20% (è¯¯å·®/Cv, è¶Šå°è¶Šå¥½)
    """
    if df is None or df.empty:
        return None
    
    result = {}
    
    # 1. RÂ² æŒ‡æ ‡ (50åˆ†)
    r2_col = 'R2' if 'R2' in df.columns else 'r2'
    if r2_col in df.columns:
        result['avg_r2'] = df[r2_col].mean()
        result['min_r2'] = df[r2_col].min()
        # RÂ²å¾—åˆ†: å¹³å‡RÂ² 40åˆ† + æœ€å°RÂ² 10åˆ†
        result['r2_score'] = result['avg_r2'] * 40 + result['min_r2'] * 10
    else:
        result['avg_r2'] = 0
        result['min_r2'] = 0
        result['r2_score'] = 0
    
    # 2. èšç±»è´¨é‡æŒ‡æ ‡ (30åˆ†)
    if 'silhouette_score' in df.columns:
        # Silhouette Score èŒƒå›´ [-1, 1], éœ€è¦å½’ä¸€åŒ–åˆ° [0, 1]
        silhouette = df['silhouette_score'].iloc[0]
        result['silhouette'] = silhouette
        # å½’ä¸€åŒ–: (silhouette + 1) / 2 * 30
        result['silhouette_score'] = max(0, (silhouette + 1) / 2) * 30
    else:
        result['silhouette'] = None
        result['silhouette_score'] = 15  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
    
    # Davies-Bouldin ä½œä¸ºå‚è€ƒ (è¶Šä½è¶Šå¥½ï¼Œä½†ä¸è®¡å…¥è¯„åˆ†)
    if 'davies_bouldin' in df.columns:
        result['davies_bouldin'] = df['davies_bouldin'].iloc[0]
    else:
        result['davies_bouldin'] = None
    
    # 3. Cvè¯¯å·®æŒ‡æ ‡ (20åˆ†)
    if 'Cv_cluster' in df.columns and 'Cv_cluster_err' in df.columns:
        # è®¡ç®—ç›¸å¯¹è¯¯å·® (è¯¯å·®/Cv)
        valid = df['Cv_cluster'].abs() > 0.01
        if valid.any():
            error_ratios = (df.loc[valid, 'Cv_cluster_err'].abs() / 
                           df.loc[valid, 'Cv_cluster'].abs())
            result['cv_error_ratio'] = error_ratios.mean()
            # è¯¯å·®å¾—åˆ†: è¯¯å·®æ¯”è¶Šå°åˆ†æ•°è¶Šé«˜
            # å‡è®¾è¯¯å·®æ¯” < 0.05 ä¸ºä¼˜ç§€(20åˆ†), > 0.2 ä¸ºå·®(0åˆ†)
            result['error_score'] = max(0, min(20, (0.2 - result['cv_error_ratio']) / 0.15 * 20))
        else:
            result['cv_error_ratio'] = 0
            result['error_score'] = 20
    else:
        result['cv_error_ratio'] = None
        result['error_score'] = 10  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
    
    # 4. çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§ (æ–°æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°å¤šåˆ†åŒºæ˜¯å¦æœ‰æ„ä¹‰)
    result['cv_diff_significant'] = True  # é»˜è®¤æ˜¾è‘—
    result['cv_values'] = []
    result['cv_errors'] = []
    result['cv_diff_ratio'] = None
    
    if 'Cv_cluster' in df.columns and 'Cv_cluster_err' in df.columns:
        cv_values = df['Cv_cluster'].values
        cv_errors = df['Cv_cluster_err'].values
        result['cv_values'] = cv_values.tolist()
        result['cv_errors'] = cv_errors.tolist()
        
        if len(cv_values) >= 2:
            # è®¡ç®—ç›¸é‚»åˆ†åŒºçš„çƒ­å®¹å·®å¼‚
            cv_diffs = []
            for i in range(len(cv_values) - 1):
                diff = abs(cv_values[i+1] - cv_values[i])
                # åˆå¹¶è¯¯å·® (è¯¯å·®ä¼ æ’­)
                combined_err = np.sqrt(cv_errors[i]**2 + cv_errors[i+1]**2)
                # å·®å¼‚æ˜¾è‘—æ€§: å·®å¼‚æ˜¯å¦å¤§äº2å€åˆå¹¶è¯¯å·®
                significant = diff > 2 * combined_err
                cv_diffs.append({
                    'diff': diff,
                    'combined_err': combined_err,
                    'significant': significant,
                    'ratio': diff / combined_err if combined_err > 0 else float('inf')
                })
            
            result['cv_diffs'] = cv_diffs
            
            # å¯¹äº2åˆ†åŒºå’Œ3åˆ†åŒºéƒ½è®¡ç®—çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§
            if len(cv_values) == 2:  # 2åˆ†åŒº
                result['cv_diff_significant'] = cv_diffs[0]['significant']
                result['cv_diff_ratio'] = cv_diffs[0]['ratio']
            elif len(cv_values) == 3:  # 3åˆ†åŒº
                # æ£€æŸ¥partition2å’Œpartition3çš„å·®å¼‚
                last_diff = cv_diffs[-1]
                result['cv_diff_significant'] = last_diff['significant']
                result['cv_diff_ratio'] = last_diff['ratio']
    
    # ç»¼åˆå¾—åˆ†
    result['total_score'] = result['r2_score'] + result['silhouette_score'] + result['error_score']
    
    return result


def analyze_all_structures(results_dir):
    """åˆ†ææ‰€æœ‰ç»“æ„çš„åˆ†åŒºè´¨é‡ - ç»¼åˆè¯„åˆ† (åŒ…å«1åˆ†åŒºåŸºå‡†)"""
    data = load_quality_metrics(results_dir)
    results_dir = Path(results_dir)
    
    analysis_results = []
    
    for structure in sorted(data.keys()):
        partitions = data[structure]
        
        result = {
            'structure': structure,
            # n=1 æŒ‡æ ‡ (æ•´ä½“æ‹Ÿåˆ)
            'n1_r2': 0,
            'n1_score': 0,  # ç®€åŒ–å¾—åˆ† = RÂ² * 50
            # n=2 æŒ‡æ ‡
            'auto2_score': 0,
            'auto2_avg_r2': 0,
            'auto2_min_r2': 0,
            'auto2_silhouette': None,
            'auto2_error_ratio': None,
            'auto2_cv_values': [],
            # n=3 æŒ‡æ ‡
            'auto3_score': 0,
            'auto3_avg_r2': 0,
            'auto3_min_r2': 0,
            'auto3_silhouette': None,
            'auto3_error_ratio': None,
            'auto3_cv_values': [],
            'auto3_cv_diff_significant': True,  # 3åˆ†åŒºçƒ­å®¹å·®å¼‚æ˜¯å¦æ˜¾è‘—
            'auto3_cv_diff_ratio': None,  # çƒ­å®¹å·®å¼‚/åˆå¹¶è¯¯å·®
            # RÂ²å¢ç›Š (ç›¸å¯¹äº1åˆ†åŒº)
            'n2_r2_gain': 0,  # n2 RÂ² - n1 RÂ²
            'n3_r2_gain': 0,  # n3 RÂ² - n1 RÂ²
            # å†³ç­–
            'score_diff': 0,  # auto2 - auto3ï¼Œæ­£å€¼è¡¨ç¤ºn=2æ›´ä¼˜
            'r2_diff': 0,
            'partition_meaningful': True,  # åˆ†åŒºæ˜¯å¦æœ‰æ„ä¹‰
            'recommendation': 'N/A',
            'confidence': 'low',
            'reason': ''
        }
        
        # åˆ†æ1åˆ†åŒº (æ•´ä½“æ‹Ÿåˆ)
        n1_info = calculate_single_partition_r2(results_dir, structure)
        if n1_info:
            result['n1_r2'] = n1_info['r2']
            result['n1_score'] = n1_info['r2'] * 50  # RÂ²æ»¡åˆ†50åˆ†
        
        # åˆ†æ2åˆ†åŒº
        if 'auto2' in partitions:
            metrics2 = calculate_comprehensive_score(partitions['auto2'])
            if metrics2:
                result['auto2_score'] = metrics2['total_score']
                result['auto2_avg_r2'] = metrics2['avg_r2']
                result['auto2_min_r2'] = metrics2['min_r2']
                result['auto2_silhouette'] = metrics2['silhouette']
                result['auto2_error_ratio'] = metrics2['cv_error_ratio']
                result['auto2_cv_values'] = metrics2.get('cv_values', [])
                result['auto2_cv_errors'] = metrics2.get('cv_errors', [])
                result['auto2_cv_diff_significant'] = metrics2.get('cv_diff_significant', True)
                result['auto2_cv_diff_ratio'] = metrics2.get('cv_diff_ratio', None)
        
        # åˆ†æ3åˆ†åŒº
        if 'auto3' in partitions:
            metrics3 = calculate_comprehensive_score(partitions['auto3'])
            if metrics3:
                result['auto3_score'] = metrics3['total_score']
                result['auto3_avg_r2'] = metrics3['avg_r2']
                result['auto3_min_r2'] = metrics3['min_r2']
                result['auto3_silhouette'] = metrics3['silhouette']
                result['auto3_error_ratio'] = metrics3['cv_error_ratio']
                result['auto3_cv_values'] = metrics3.get('cv_values', [])
                result['auto3_cv_diff_significant'] = metrics3.get('cv_diff_significant', True)
                result['auto3_cv_diff_ratio'] = metrics3.get('cv_diff_ratio', None)
                result['auto3_silhouette'] = metrics3['silhouette']
                result['auto3_error_ratio'] = metrics3['cv_error_ratio']
        
        # è®¡ç®—RÂ²å¢ç›Š (ç›¸å¯¹äº1åˆ†åŒº)
        if result['n1_r2'] > 0:
            result['n2_r2_gain'] = result['auto2_avg_r2'] - result['n1_r2']
            result['n3_r2_gain'] = result['auto3_avg_r2'] - result['n1_r2']
        
        # è®¡ç®—å·®å¼‚ (2åˆ†åŒº vs 3åˆ†åŒº)
        result['score_diff'] = result['auto2_score'] - result['auto3_score']
        result['r2_diff'] = result['auto2_avg_r2'] - result['auto3_avg_r2']
        
        # å†³ç­–é€»è¾‘ - ç»¼åˆè€ƒè™‘RÂ²ã€çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§å’Œç»¼åˆå¾—åˆ†
        if result['auto2_score'] > 0 and result['auto3_score'] > 0:
            score_diff = result['score_diff']
            
            # è·å–2åˆ†åŒºçƒ­å®¹å·®å¼‚ä¿¡æ¯
            auto2_cv_significant = result.get('auto2_cv_diff_significant', True)
            auto2_cv_ratio = result.get('auto2_cv_diff_ratio', None)
            
            # é¦–å…ˆåˆ¤æ–­åˆ†åŒºæ˜¯å¦æœ‰æ„ä¹‰ï¼š
            # 1. å¦‚æœ2åˆ†åŒºçƒ­å®¹å·®å¼‚æ˜¾è‘— (ratio >= 2)ï¼Œåˆ†åŒºæœ‰ç‰©ç†æ„ä¹‰
            # 2. å¦‚æœçƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼Œä½†RÂ²å¢ç›Šå¤§ï¼Œä¹Ÿå¯èƒ½æœ‰æ„ä¹‰
            if auto2_cv_significant and auto2_cv_ratio is not None and auto2_cv_ratio >= 2:
                # çƒ­å®¹å·®å¼‚æ˜¾è‘—ï¼Œåˆ†åŒºæœ‰ç‰©ç†æ„ä¹‰
                result['partition_meaningful'] = True
            elif result['n1_r2'] > 0 and result['n2_r2_gain'] >= 0.02:
                # RÂ²å¢ç›Šè¶³å¤Ÿ
                result['partition_meaningful'] = True
            else:
                # çƒ­å®¹å·®å¼‚ä¸æ˜¾è‘— ä¸” RÂ²å¢ç›Šä¸è¶³
                result['partition_meaningful'] = False
            
            # å†³ç­–
            if not result['partition_meaningful']:
                result['recommendation'] = '1åˆ†åŒº'
                cv_ratio_str = f'{auto2_cv_ratio:.2f}' if auto2_cv_ratio else 'N/A'
                result['confidence'] = 'high'
                result['reason'] = f'çƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—(æ¯”å€¼={cv_ratio_str}),RÂ²å¢ç›Š={result["n2_r2_gain"]:.4f}'
            
            else:
                # åˆ†åŒºæœ‰æ„ä¹‰ï¼Œæ¯”è¾ƒ2åˆ†åŒº vs 3åˆ†åŒº
                # æ ¸å¿ƒåˆ¤æ®ï¼š3åˆ†åŒºçš„çƒ­å®¹å·®å¼‚æ˜¯å¦æ˜¾è‘—ï¼ˆpartition2 vs partition3ï¼‰
                auto3_cv_significant = result.get('auto3_cv_diff_significant', True)
                auto3_cv_ratio = result.get('auto3_cv_diff_ratio', None)
                
                # å¦‚æœ3åˆ†åŒºçƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼Œç›´æ¥é€‰2åˆ†åŒº
                if not auto3_cv_significant:
                    result['recommendation'] = '2åˆ†åŒº'
                    result['confidence'] = 'high'
                    ratio_str = f'{auto3_cv_ratio:.2f}' if auto3_cv_ratio else 'N/A'
                    result['reason'] = f'3åˆ†åŒºçƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—(æ¯”å€¼={ratio_str}<2),é€‰n=2'
                
                # 3åˆ†åŒºçƒ­å®¹å·®å¼‚æ˜¾è‘—ï¼Œæ ¹æ®ç»¼åˆå¾—åˆ†å†³å®š
                elif score_diff > 2:
                    # n=2ç»¼åˆå¾—åˆ†æ›´ä¼˜
                    result['recommendation'] = '2åˆ†åŒº'
                    result['confidence'] = 'high' if score_diff > 5 else 'medium'
                    result['reason'] = f'ç»¼åˆå¾—åˆ†å·®={score_diff:+.1f}, n=2æ›´ä¼˜'
                
                elif score_diff >= -2:
                    # å·®å¼‚ä¸æ˜¾è‘—ï¼Œé»˜è®¤n=2ï¼ˆæ›´ç®€æ´çš„æ¨¡å‹ï¼‰
                    result['recommendation'] = '2åˆ†åŒº'
                    result['confidence'] = 'low'
                    result['reason'] = f'ç»¼åˆå¾—åˆ†å·®={score_diff:+.1f}, å·®å¼‚ä¸æ˜¾è‘—,é»˜è®¤n=2'
                
                else:
                    # n=3ç»¼åˆå¾—åˆ†æ›´ä¼˜ï¼Œä¸”çƒ­å®¹å·®å¼‚æ˜¾è‘—
                    result['recommendation'] = '3åˆ†åŒº'
                    result['confidence'] = 'high' if score_diff < -5 else 'medium'
                    ratio_str = f'{auto3_cv_ratio:.2f}' if auto3_cv_ratio else 'N/A'
                    result['reason'] = f'ç»¼åˆå¾—åˆ†å·®={score_diff:+.1f}, 3åˆ†åŒºçƒ­å®¹æ˜¾è‘—(æ¯”å€¼={ratio_str})'
        
        elif result['auto2_score'] > 0:
            result['recommendation'] = '2åˆ†åŒº'
            result['confidence'] = 'medium'
            result['reason'] = 'ä»…æœ‰2åˆ†åŒºæ•°æ®'
        
        elif result['auto3_score'] > 0:
            result['recommendation'] = '3åˆ†åŒº'
            result['confidence'] = 'medium'
            result['reason'] = 'ä»…æœ‰3åˆ†åŒºæ•°æ®'
        
        analysis_results.append(result)
    
    return analysis_results


def generate_report(analysis_results, output_path):
    """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š (å«1åˆ†åŒºåŸºå‡†å¯¹æ¯”)"""
    
    # åˆ†ç±»ç»Ÿè®¡
    total = len(analysis_results)
    n2_better = sum(1 for r in analysis_results if r['score_diff'] > 0)
    n3_better = sum(1 for r in analysis_results if r['score_diff'] < 0)
    partition_meaningful = sum(1 for r in analysis_results if r['partition_meaningful'])
    partition_not_meaningful = total - partition_meaningful
    
    valid_n1 = [r['n1_r2'] for r in analysis_results if r['n1_r2'] > 0]
    valid_n2 = [r['auto2_avg_r2'] for r in analysis_results if r['auto2_avg_r2'] > 0]
    valid_n3 = [r['auto3_avg_r2'] for r in analysis_results if r['auto3_avg_r2'] > 0]
    avg_r2_n1 = np.mean(valid_n1) if valid_n1 else 0
    avg_r2_n2 = np.mean(valid_n2) if valid_n2 else 0
    avg_r2_n3 = np.mean(valid_n3) if valid_n3 else 0
    
    valid_n2_gain = [r['n2_r2_gain'] for r in analysis_results if r['n1_r2'] > 0]
    valid_n3_gain = [r['n3_r2_gain'] for r in analysis_results if r['n1_r2'] > 0]
    avg_n2_gain = np.mean(valid_n2_gain) if valid_n2_gain else 0
    avg_n3_gain = np.mean(valid_n3_gain) if valid_n3_gain else 0
    
    valid_score_n2 = [r['auto2_score'] for r in analysis_results if r['auto2_score'] > 0]
    valid_score_n3 = [r['auto3_score'] for r in analysis_results if r['auto3_score'] > 0]
    avg_score_n2 = np.mean(valid_score_n2) if valid_score_n2 else 0
    avg_score_n3 = np.mean(valid_score_n3) if valid_score_n3 else 0
    
    sig_n2 = sum(1 for r in analysis_results if r['score_diff'] > 5)
    sig_n3 = sum(1 for r in analysis_results if r['score_diff'] < -5)
    marginal = sum(1 for r in analysis_results if -2 <= r['score_diff'] <= 2)
    
    recommend_1 = [r for r in analysis_results if r['recommendation'] == '1åˆ†åŒº']
    recommend_2 = [r for r in analysis_results if r['recommendation'] == '2åˆ†åŒº']
    recommend_3 = [r for r in analysis_results if r['recommendation'] == '3åˆ†åŒº']
    high_conf = [r for r in analysis_results if r['confidence'] == 'high']
    
    report = f"""# åˆ†åŒºç­–ç•¥ç»¼åˆåˆ†ææŠ¥å‘Š (1/2/3åˆ†åŒºå¯¹æ¯”)

**ç”Ÿæˆæ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}  
**åˆ†æä½“ç³»æ•°**: {total}  
**åˆ†æè„šæœ¬ç‰ˆæœ¬**: v2.2

---

## ğŸ¯ æ ¸å¿ƒç»“è®º

> **ç»Ÿä¸€ä½¿ç”¨ n=2ï¼ˆä¸¤ç›¸åˆ†åŒºï¼‰æ˜¯åˆç†çš„é€‰æ‹©**

åŸºäº 1åˆ†åŒº(æ•´ä½“æ‹Ÿåˆ) vs 2åˆ†åŒº vs 3åˆ†åŒº çš„ç»¼åˆå¯¹æ¯”åˆ†æã€‚

---

## ğŸ“Š 1åˆ†åŒº vs 2åˆ†åŒº vs 3åˆ†åŒº RÂ² å¯¹æ¯”

**âš ï¸ RÂ²å«ä¹‰è¯´æ˜**ï¼š
- **n=1 RÂ²**: å¯¹æ‰€æœ‰æ¸©åº¦ç‚¹æ•´ä½“çº¿æ€§æ‹Ÿåˆï¼ˆæ¸©åº¦ vs å¹³å‡èƒ½é‡ï¼‰çš„RÂ²
- **n=2/n=3 RÂ²**: åˆ†åŒºåï¼Œæ¯ä¸ªåˆ†åŒºå†…éƒ¨çº¿æ€§æ‹Ÿåˆçš„**å¹³å‡RÂ²**

ç”±äºn=1æ˜¯å…¨å±€æ‹Ÿåˆï¼Œn=2/n=3æ˜¯å±€éƒ¨æ‹Ÿåˆï¼Œä¸¤è€…RÂ²ä¸èƒ½ç›´æ¥æ¯”è¾ƒï¼

| åˆ†åŒºæ•° | å¹³å‡RÂ² | RÂ²å·®å¼‚ | è¯´æ˜ |
|--------|--------|--------|------|
| **n=1 (æ•´ä½“æ‹Ÿåˆ)** | {avg_r2_n1:.4f} | - | å…¨å±€çº¿æ€§æ‹Ÿåˆ |
| **n=2** | {avg_r2_n2:.4f} | {avg_n2_gain:+.4f} | åˆ†åŒºåå±€éƒ¨æ‹Ÿåˆå¹³å‡ |
| **n=3** | {avg_r2_n3:.4f} | {avg_n3_gain:+.4f} | åˆ†åŒºåå±€éƒ¨æ‹Ÿåˆå¹³å‡ |

### åˆ†åŒºæ„ä¹‰è¯„ä¼°ï¼ˆåŸºäºçƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§ï¼‰

**æ ¸å¿ƒåˆ¤æ®**ï¼š2åˆ†åŒºçš„ä¸¤ä¸ªåˆ†åŒºçƒ­å®¹å·®å¼‚æ˜¯å¦ç»Ÿè®¡æ˜¾è‘—ï¼ˆ|Cvâ‚-Cvâ‚‚| / âˆš(errâ‚Â²+errâ‚‚Â²) â‰¥ 2ï¼‰

| è¯„ä¼°ç»“æœ | æ•°é‡ | å æ¯” | è¯´æ˜ |
|----------|------|------|------|
| **åˆ†åŒºæœ‰æ„ä¹‰** | {partition_meaningful} | {100*partition_meaningful/total:.1f}% | çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§æ¯”å€¼ â‰¥ 2 |
| åˆ†åŒºæ„ä¹‰ä¸å¤§ | {partition_not_meaningful} | {100*partition_not_meaningful/total:.1f}% | çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§æ¯”å€¼ < 2 |

---

## ğŸ“Š è¯„åˆ†å…¬å¼

ç»¼åˆå¾—åˆ† (0-100åˆ†) = RÂ²å¾—åˆ† (50åˆ†) + èšç±»è´¨é‡ (30åˆ†) + è¯¯å·®å¾—åˆ† (20åˆ†)

| æŒ‡æ ‡ | æƒé‡ | è®¡ç®—æ–¹å¼ |
|------|------|----------|
| **å¹³å‡RÂ²** | 40% | avg_RÂ² Ã— 40 |
| **æœ€å°RÂ²** | 10% | min_RÂ² Ã— 10 |
| **Silhouette Score** | 30% | (silhouette+1)/2 Ã— 30 |
| **Cvè¯¯å·®æ¯”ä¾‹** | 20% | (0.2-error_ratio)/0.15 Ã— 20 |

---

## ğŸ“Š ç»Ÿè®¡æ‘˜è¦

### æ€»ä½“å¯¹æ¯”

| æŒ‡æ ‡ | n=2 | n=3 | å·®å¼‚ |
|------|-----|-----|------|
| **æ›´ä¼˜ç³»ç»Ÿæ•°** | {n2_better}/{total} ({100*n2_better/total:.1f}%) | {n3_better}/{total} ({100*n3_better/total:.1f}%) | n=2é¢†å…ˆ |
| **å¹³å‡ç»¼åˆå¾—åˆ†** | {avg_score_n2:.1f} | {avg_score_n3:.1f} | {avg_score_n2-avg_score_n3:+.1f} |
| **å¹³å‡RÂ²** | {avg_r2_n2:.4f} | {avg_r2_n3:.4f} | {avg_r2_n2-avg_r2_n3:+.4f} |

### ç»¼åˆå¾—åˆ†å·®å¼‚åˆ†å¸ƒ

| å·®å¼‚ç±»å‹ | æ•°é‡ | å æ¯” | è¯´æ˜ |
|----------|------|------|------|
| n=2**æ˜¾è‘—**æ›´ä¼˜ (diff>5) | {sig_n2} | {100*sig_n2/total:.1f}% | é«˜ç½®ä¿¡åº¦æ¨èn=2 |
| n=3**æ˜¾è‘—**æ›´ä¼˜ (diff<-5) | {sig_n3} | {100*sig_n3/total:.1f}% | é«˜ç½®ä¿¡åº¦æ¨èn=3 |
| **å·®å¼‚ä¸æ˜¾è‘—** (\\|diff\\|â‰¤2) | {marginal} | {100*marginal/total:.1f}% | é»˜è®¤ä½¿ç”¨n=2 |

### æœ€ç»ˆæ¨è

| æ¨èåˆ†åŒº | æ•°é‡ | å æ¯” |
|----------|------|------|
| 1åˆ†åŒº | {len(recommend_1)} | {100*len(recommend_1)/total:.1f}% |
| **2åˆ†åŒº** | {len(recommend_2)} | {100*len(recommend_2)/total:.1f}% |
| 3åˆ†åŒº | {len(recommend_3)} | {100*len(recommend_3)/total:.1f}% |
| é«˜ç½®ä¿¡åº¦ | {len(high_conf)} | {100*len(high_conf)/total:.1f}% |

---

## ğŸ“‹ å®Œæ•´åˆ†åŒºæ¨èè¡¨

**åˆ—è¯´æ˜**ï¼š
- **n1 RÂ²**: æ•´ä½“çº¿æ€§æ‹ŸåˆRÂ²ï¼ˆå…¨å±€ï¼‰
- **n2 RÂ²**: 2åˆ†åŒºå„è‡ªæ‹Ÿåˆçš„å¹³å‡RÂ²ï¼ˆå±€éƒ¨ï¼‰
- **n2-n1**: n2 RÂ² - n1 RÂ²ï¼ˆé€šå¸¸ä¸ºè´Ÿï¼Œå› ä¸ºå±€éƒ¨æ‹ŸåˆRÂ²é€šå¸¸ä½äºå…¨å±€ï¼‰
- **å¾—åˆ†å·®**: n2ç»¼åˆå¾—åˆ† - n3ç»¼åˆå¾—åˆ†ï¼ˆæ­£å€¼è¡¨ç¤ºn=2æ›´ä¼˜ï¼‰

| ä½“ç³» | æ¨è | ç½®ä¿¡åº¦ | n1 RÂ² | n2 RÂ² | n3 RÂ² | n2-n1 | n2å¾—åˆ† | n3å¾—åˆ† | å¾—åˆ†å·® | ç†ç”± |
|------|------|--------|-------|-------|-------|-------|--------|--------|--------|------|
"""
    
    # æŒ‰å¾—åˆ†å·®æ’åºï¼ˆn=2æ›´ä¼˜çš„æ’å‰é¢ï¼‰
    for r in sorted(analysis_results, key=lambda x: -x['score_diff']):
        conf_icon = {'high': 'ğŸŸ¢', 'medium': 'ğŸŸ¡', 'low': 'âšª'}.get(r['confidence'], 'âšª')
        rec = '**2åˆ†åŒº**' if r['recommendation'] == '2åˆ†åŒº' else ('1åˆ†åŒº' if r['recommendation'] == '1åˆ†åŒº' else '3åˆ†åŒº')
        n1_r2 = f"{r['n1_r2']:.4f}" if r['n1_r2'] > 0 else 'N/A'
        n2_diff = f"{r['n2_r2_gain']:+.4f}" if r['n1_r2'] > 0 else 'N/A'
        report += f"| {r['structure']} | {rec} | {conf_icon} | {n1_r2} | {r['auto2_avg_r2']:.4f} | {r['auto3_avg_r2']:.4f} | {n2_diff} | {r['auto2_score']:.1f} | {r['auto3_score']:.1f} | {r['score_diff']:+.1f} | {r['reason']} |\n"
    
    # åˆ†åŒºæ„ä¹‰åˆ†æ
    report += """
---

## ğŸ” åˆ†åŒºæ„ä¹‰åˆ†æ

### åˆ†åŒºæ„ä¹‰ä¸å¤§çš„ä½“ç³»ï¼ˆçƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼‰

**åˆ¤æ–­æ ‡å‡†**: 2åˆ†åŒºçš„çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§æ¯”å€¼ = |Cvâ‚-Cvâ‚‚| / âˆš(errâ‚Â²+errâ‚‚Â²) < 2

"""
    not_meaningful = [r for r in analysis_results if not r['partition_meaningful']]
    if not_meaningful:
        report += "| ä½“ç³» | n1 RÂ² | n2 RÂ² | çƒ­å®¹å·®å¼‚æ¯”å€¼ | è¯´æ˜ |\n"
        report += "|------|-------|-------|--------------|------|\n"
        for r in sorted(not_meaningful, key=lambda x: x.get('auto2_cv_diff_ratio', 0) or 0):
            cv_ratio = r.get('auto2_cv_diff_ratio', None)
            cv_ratio_str = f"{cv_ratio:.2f}" if cv_ratio is not None else 'N/A'
            report += f"| {r['structure']} | {r['n1_r2']:.4f} | {r['auto2_avg_r2']:.4f} | {cv_ratio_str} | çƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼Œåˆ†åŒºæ— ç‰©ç†æ„ä¹‰ |\n"
    else:
        report += "*æ‰€æœ‰ä½“ç³»çš„åˆ†åŒºéƒ½æœ‰æ„ä¹‰*\n"

    # åˆ†ç³»åˆ—åˆ†æ
    report += """
---

## ğŸ“Š æŒ‰ç³»åˆ—åˆ†æ

### Pt8ç³»åˆ—

"""
    pt8_systems = [r for r in analysis_results if r['structure'].lower().startswith('pt8')]
    if pt8_systems:
        pt8_n2_better = sum(1 for r in pt8_systems if r['score_diff'] > 0)
        pt8_meaningful = sum(1 for r in pt8_systems if r['partition_meaningful'])
        report += f"**ç»Ÿè®¡**: n=2æ›´ä¼˜ {pt8_n2_better}/{len(pt8_systems)} ({100*pt8_n2_better/len(pt8_systems):.1f}%), åˆ†åŒºæœ‰æ„ä¹‰ {pt8_meaningful}/{len(pt8_systems)}\n\n"
        report += "| ä½“ç³» | æ¨è | n2-n1å·® | å¾—åˆ†å·® | RÂ²å·® | ç½®ä¿¡åº¦ |\n"
        report += "|------|------|---------|--------|------|--------|\n"
        for r in sorted(pt8_systems, key=lambda x: x['structure']):
            conf_icon = {'high': 'ğŸŸ¢', 'medium': 'ğŸŸ¡', 'low': 'âšª'}.get(r['confidence'], 'âšª')
            n2_gain = f"{r['n2_r2_gain']:.4f}" if r['n1_r2'] > 0 else 'N/A'
            report += f"| {r['structure']} | {r['recommendation']} | {n2_gain} | {r['score_diff']:+.1f} | {r['r2_diff']:+.4f} | {conf_icon} |\n"

    report += """
### Pt6ç³»åˆ—

"""
    pt6_systems = [r for r in analysis_results if r['structure'].lower().startswith('pt6')]
    if pt6_systems:
        pt6_n2_better = sum(1 for r in pt6_systems if r['score_diff'] > 0)
        pt6_meaningful = sum(1 for r in pt6_systems if r['partition_meaningful'])
        report += f"**ç»Ÿè®¡**: n=2æ›´ä¼˜ {pt6_n2_better}/{len(pt6_systems)} ({100*pt6_n2_better/len(pt6_systems):.1f}%), åˆ†åŒºæœ‰æ„ä¹‰ {pt6_meaningful}/{len(pt6_systems)}\n\n"
        report += "| ä½“ç³» | æ¨è | n2-n1å·® | å¾—åˆ†å·® | RÂ²å·® | ç½®ä¿¡åº¦ |\n"
        report += "|------|------|---------|--------|------|--------|\n"
        for r in sorted(pt6_systems, key=lambda x: x['structure']):
            conf_icon = {'high': 'ğŸŸ¢', 'medium': 'ğŸŸ¡', 'low': 'âšª'}.get(r['confidence'], 'âšª')
            n2_diff = f"{r['n2_r2_gain']:+.4f}" if r['n1_r2'] > 0 else 'N/A'
            report += f"| {r['structure']} | {r['recommendation']} | {n2_diff} | {r['score_diff']:+.1f} | {r['r2_diff']:+.4f} | {conf_icon} |\n"

    report += """
### å…¶ä»–ç³»åˆ—

"""
    other_systems = [r for r in analysis_results 
                     if not r['structure'].lower().startswith('pt8') 
                     and not r['structure'].lower().startswith('pt6')]
    if other_systems:
        other_n2_better = sum(1 for r in other_systems if r['score_diff'] > 0)
        other_meaningful = sum(1 for r in other_systems if r['partition_meaningful'])
        report += f"**ç»Ÿè®¡**: n=2æ›´ä¼˜ {other_n2_better}/{len(other_systems)} ({100*other_n2_better/len(other_systems):.1f}%), åˆ†åŒºæœ‰æ„ä¹‰ {other_meaningful}/{len(other_systems)}\n\n"
        report += "| ä½“ç³» | æ¨è | n2-n1å·® | å¾—åˆ†å·® | RÂ²å·® | ç½®ä¿¡åº¦ |\n"
        report += "|------|------|---------|--------|------|--------|\n"
        for r in sorted(other_systems, key=lambda x: x['structure']):
            conf_icon = {'high': 'ğŸŸ¢', 'medium': 'ğŸŸ¡', 'low': 'âšª'}.get(r['confidence'], 'âšª')
            n2_diff = f"{r['n2_r2_gain']:+.4f}" if r['n1_r2'] > 0 else 'N/A'
            report += f"| {r['structure']} | {r['recommendation']} | {n2_diff} | {r['score_diff']:+.1f} | {r['r2_diff']:+.4f} | {conf_icon} |\n"

    report += f"""
---

## ğŸ“ å†³ç­–æ ‡å‡†ä¸é€»è¾‘è§£é‡Š

### ğŸ“Œ æ ¸å¿ƒé—®é¢˜ï¼š1åˆ†åŒºæ²¡æœ‰èšç±»è´¨é‡åˆ†

**é‡è¦è¯´æ˜**ï¼š
- **1åˆ†åŒº** = æ•´ä½“çº¿æ€§æ‹Ÿåˆï¼Œæ²¡æœ‰èšç±»ï¼Œåªæœ‰RÂ²
- **2/3åˆ†åŒº** = K-meansèšç±» + åˆ†æ®µçº¿æ€§æ‹Ÿåˆï¼Œæœ‰å®Œæ•´çš„ç»¼åˆå¾—åˆ†ï¼ˆRÂ² + Silhouette + è¯¯å·®ï¼‰

å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨**ä¸‰é˜¶æ®µå†³ç­–**ï¼ˆæ ¸å¿ƒï¼šçƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§æ£€éªŒï¼‰ï¼š

### ç¬¬ä¸€é˜¶æ®µï¼šè®¡ç®—1åˆ†åŒºæ•´ä½“æ‹ŸåˆRÂ²

å¯¹æ‰€æœ‰æ•°æ®è¿›è¡Œæ•´ä½“çº¿æ€§æ‹Ÿåˆï¼ˆæ¸©åº¦ vs å¹³å‡èƒ½é‡ï¼‰ï¼Œè®¡ç®—RÂ²ä½œä¸ºåŸºå‡†ã€‚

### ç¬¬äºŒé˜¶æ®µï¼šåˆ¤æ–­2åˆ†åŒºæ˜¯å¦æœ‰ç‰©ç†æ„ä¹‰ (n=1 vs n=2)

**çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§æ£€éªŒ**ï¼š

$$\\text{{æ˜¾è‘—æ€§æ¯”å€¼}} = \\frac{{|Cv_1 - Cv_2|}}{{\\sqrt{{err_1^2 + err_2^2}}}}$$

| æ˜¾è‘—æ€§æ¯”å€¼ | åˆ¤å®š | ç†ç”± |
|------------|------|------|
| **æ¯”å€¼ < 2** | æ¨èn=1 | 2åˆ†åŒºçƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼Œåˆ†åŒºæ— ç‰©ç†æ„ä¹‰ |
| **æ¯”å€¼ â‰¥ 2** | ç»§ç»­ç¬¬ä¸‰é˜¶æ®µ | çƒ­å®¹å·®å¼‚æ˜¾è‘—ï¼Œéœ€åˆ¤æ–­2åˆ†åŒºè¿˜æ˜¯3åˆ†åŒº |

### ç¬¬ä¸‰é˜¶æ®µï¼šåˆ¤æ–­3åˆ†åŒºæ˜¯å¦æœ‰ç‰©ç†æ„ä¹‰ (n=2 vs n=3)

**åŒæ ·ä½¿ç”¨çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§æ£€éªŒ**ï¼š

$$\\text{{æ˜¾è‘—æ€§æ¯”å€¼}} = \\frac{{|Cv_2 - Cv_3|}}{{\\sqrt{{err_2^2 + err_3^2}}}}$$

| æ˜¾è‘—æ€§æ¯”å€¼ | åˆ¤å®š | ç†ç”± |
|------------|------|------|
| **æ¯”å€¼ < 2** | æ¨èn=2 | 3åˆ†åŒºçš„ç¬¬2ã€3åŒºçƒ­å®¹å·®å¼‚ä¸æ˜¾è‘— |
| **æ¯”å€¼ â‰¥ 2** | ç»“åˆç»¼åˆå¾—åˆ† | çƒ­å®¹å·®å¼‚æ˜¾è‘—ï¼Œæ ¹æ®ç»¼åˆå¾—åˆ†é€‰æ‹© |

### ğŸ’¡ ç»Ÿä¸€çš„çƒ­å®¹å·®å¼‚æ£€éªŒåŸåˆ™

æ— è®ºæ˜¯1â†’2åˆ†åŒºè¿˜æ˜¯2â†’3åˆ†åŒºï¼Œæ ¸å¿ƒåˆ¤æ®éƒ½æ˜¯ï¼š

> **çƒ­å®¹å·®å¼‚ / åˆå¹¶è¯¯å·® â‰¥ 2** â†’ åˆ†åŒºæœ‰ç‰©ç†æ„ä¹‰

è¿™ç¡®ä¿äº†ï¼š
1. æ¯æ¬¡å¢åŠ åˆ†åŒºæ•°ï¼Œéƒ½å¿…é¡»å¸¦æ¥**ç»Ÿè®¡æ˜¾è‘—çš„çƒ­å®¹å·®å¼‚**
2. é¿å…è¿‡åº¦æ‹Ÿåˆï¼ˆåˆ†åŒºè¶Šå¤šä½†çƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼‰

### ï¿½ ç¤ºä¾‹

**Air68ä½“ç³»**ï¼ˆæ¨è1åˆ†åŒºï¼‰ï¼š
- 2åˆ†åŒºçƒ­å®¹: Cvâ‚ = 1.23 Â± 0.05, Cvâ‚‚ = 1.35 Â± 0.08
- æ˜¾è‘—æ€§æ¯”å€¼ = |1.35-1.23| / âˆš(0.05Â²+0.08Â²) = 0.12/0.094 = **0.71 < 2**
- ç»“è®ºï¼šçƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼Œåˆ†åŒºæ— æ„ä¹‰

**Pt8sn6ä½“ç³»**ï¼ˆæ¨è2åˆ†åŒºï¼‰ï¼š
- 2åˆ†åŒºçƒ­å®¹å·®å¼‚æ˜¾è‘—ï¼ˆæ¯”å€¼ â‰¥ 2ï¼‰
- 3åˆ†åŒºçƒ­å®¹å·®å¼‚ä¸æ˜¾è‘—ï¼ˆæ¯”å€¼ < 2ï¼‰
- ç»“è®ºï¼š2åˆ†åŒºæœ‰ç‰©ç†æ„ä¹‰ï¼Œ3åˆ†åŒºæ— å¿…è¦

---

## ğŸ”§ ä½¿ç”¨å‘½ä»¤

æ‰¹é‡ä½¿ç”¨2åˆ†åŒºè¿è¡Œæ‰€æœ‰ä½“ç³»ï¼š
```bash
python step6_2_run_batch_analysis.py
```

å•ä¸ªä½“ç³»ä½¿ç”¨2åˆ†åŒºï¼š
```bash
python step6_1_clustering_analysis.py -s <ç»“æ„å> -n 2 --use-d-value
```

---

*æŠ¥å‘Šç”± `analyze_partition_recommendations.py v2.4` è‡ªåŠ¨ç”Ÿæˆ*
"""
    
    # ä¿å­˜æŠ¥å‘Š
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"[SUCCESS] æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")
    
    return report


def main():
    results_dir = Path(__file__).parent / 'results' / 'step6_1_clustering'
    output_path = results_dir / 'PARTITION_RECOMMENDATION_REPORT.md'
    
    print("=" * 70)
    print("åˆ†åŒºç­–ç•¥åˆ†æ v2.4 - å«çƒ­å®¹å·®å¼‚æ˜¾è‘—æ€§æ£€éªŒ")
    print("=" * 70)
    
    # åˆ†ææ‰€æœ‰ç»“æ„
    analysis_results = analyze_all_structures(results_dir)
    
    if not analysis_results:
        print("[ERROR] æœªæ‰¾åˆ°ä»»ä½•åˆ†æç»“æœ!")
        return
    
    print(f"\n[INFO] åˆ†æäº† {len(analysis_results)} ä¸ªä½“ç³»")
    
    # 1åˆ†åŒº vs 2åˆ†åŒº vs 3åˆ†åŒº RÂ² ç»Ÿè®¡
    valid_n1 = [r['n1_r2'] for r in analysis_results if r['n1_r2'] > 0]
    valid_n2 = [r['auto2_avg_r2'] for r in analysis_results if r['auto2_avg_r2'] > 0]
    valid_n3 = [r['auto3_avg_r2'] for r in analysis_results if r['auto3_avg_r2'] > 0]
    
    print(f"\n[RÂ² å¯¹æ¯”]")
    if valid_n1:
        avg_r2_n1 = np.mean(valid_n1)
        avg_r2_n2 = np.mean(valid_n2) if valid_n2 else 0
        avg_r2_n3 = np.mean(valid_n3) if valid_n3 else 0
        print(f"  n=1 (æ•´ä½“æ‹Ÿåˆ): å¹³å‡RÂ² = {avg_r2_n1:.4f}")
        print(f"  n=2:             å¹³å‡RÂ² = {avg_r2_n2:.4f} (+{avg_r2_n2-avg_r2_n1:.4f})")
        print(f"  n=3:             å¹³å‡RÂ² = {avg_r2_n3:.4f} (+{avg_r2_n3-avg_r2_n1:.4f})")
    
    # åˆ†åŒºæ„ä¹‰ç»Ÿè®¡
    partition_meaningful = sum(1 for r in analysis_results if r['partition_meaningful'])
    print(f"\n[åˆ†åŒºæ„ä¹‰]")
    print(f"  åˆ†åŒºæœ‰æ„ä¹‰: {partition_meaningful}/{len(analysis_results)} ({100*partition_meaningful/len(analysis_results):.1f}%)")
    print(f"  åˆ†åŒºæ„ä¹‰ä¸å¤§: {len(analysis_results)-partition_meaningful}/{len(analysis_results)} ({100*(len(analysis_results)-partition_meaningful)/len(analysis_results):.1f}%)")
    
    # ç»Ÿè®¡æ‘˜è¦
    n2_better = sum(1 for r in analysis_results if r['score_diff'] > 0)
    n3_better = sum(1 for r in analysis_results if r['score_diff'] < 0)
    
    valid_score_n2 = [r['auto2_score'] for r in analysis_results if r['auto2_score'] > 0]
    valid_score_n3 = [r['auto3_score'] for r in analysis_results if r['auto3_score'] > 0]
    avg_score_n2 = np.mean(valid_score_n2) if valid_score_n2 else 0
    avg_score_n3 = np.mean(valid_score_n3) if valid_score_n3 else 0
    
    print(f"\n[n=2 vs n=3 å¯¹æ¯”]")
    print(f"  n=2 æ›´ä¼˜: {n2_better}/{len(analysis_results)} ({100*n2_better/len(analysis_results):.1f}%)")
    print(f"  n=3 æ›´ä¼˜: {n3_better}/{len(analysis_results)} ({100*n3_better/len(analysis_results):.1f}%)")
    print(f"  å¹³å‡ç»¼åˆå¾—åˆ†: n2={avg_score_n2:.1f} vs n3={avg_score_n3:.1f} (å·®å¼‚: {avg_score_n2-avg_score_n3:+.1f})")
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_report(analysis_results, output_path)
    
    # æ¨èæ‘˜è¦
    recommend_1 = [r for r in analysis_results if r['recommendation'] == '1åˆ†åŒº']
    recommend_2 = [r for r in analysis_results if r['recommendation'] == '2åˆ†åŒº']
    recommend_3 = [r for r in analysis_results if r['recommendation'] == '3åˆ†åŒº']
    
    print(f"\n[RECOMMENDATION]")
    print(f"  æ¨è1åˆ†åŒº: {len(recommend_1)} ä¸ªä½“ç³»")
    print(f"  æ¨è2åˆ†åŒº: {len(recommend_2)} ä¸ªä½“ç³»")
    print(f"  æ¨è3åˆ†åŒº: {len(recommend_3)} ä¸ªä½“ç³»")
    print(f"\n>>> ç»“è®º: ç»Ÿä¸€ä½¿ç”¨ n=2 (ä¸¤ç›¸åˆ†åŒº) æ˜¯åˆç†çš„é€‰æ‹©")


if __name__ == '__main__':
    main()
