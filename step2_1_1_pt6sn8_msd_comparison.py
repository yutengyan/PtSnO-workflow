#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 2.1.1: è´Ÿè½½å‹ Pt6Sn8 MSD å¯¹æ¯”å›¾ (300K vs 900K)

åªç»˜åˆ¶ PtSn æ•´ä½“çš„ MSD æ›²çº¿:
- 300K: è“è‰²
- 900K: çº¢è‰²
- å¤šæ¬¡æ¨¡æ‹Ÿå¹³å‡ + è¯¯å·®å¸¦
- å¯¼å‡ºç»˜å›¾æ•°æ®åˆ° CSV
- æ”¯æŒæ’é™¤ Step1 æ£€æµ‹çš„å¼‚å¸¸ run

Author: AI Assistant
Date: 2025-12-01
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
import re
import warnings
from collections import defaultdict
from scipy.signal import savgol_filter

warnings.filterwarnings('ignore')

# ===== æ•°æ®é›†é€‰æ‹© =====
# å¯é€‰: 'pt6sn8' (è´Ÿè½½å‹Pt6Sn8) æˆ– 'cv' (Pt6Sn8O4)
DATASET = 'pt6sn8'  # ğŸ”§ ä¿®æ”¹æ­¤å¤„åˆ‡æ¢æ•°æ®é›†

# ===== å¼‚å¸¸æ’é™¤å¼€å…³ =====
EXCLUDE_OUTLIERS = False  # ğŸ”§ æ˜¯å¦æ’é™¤ Step1 æ£€æµ‹çš„å¼‚å¸¸ run (åŸºäº large_D_outliers.csv)
OUTLIER_CSV = Path(__file__).parent / 'results' / 'large_D_outliers.csv'

# ===== å†…ç½® IQR å¼‚å¸¸è¿‡æ»¤ =====
APPLY_IQR_FILTER = False   # ğŸ”§ æ˜¯å¦åœ¨è®¡ç®—ç³»ç»¼å¹³å‡æ—¶åº”ç”¨ IQR è¿‡æ»¤ (æ¨èå¼€å¯)
IQR_MULTIPLIER = 1.0      # IQR å€æ•° (1.5 = æ ‡å‡†, 1.0 = ä¸¥æ ¼)

# æ•°æ®é›†é…ç½®
DATASET_CONFIGS = {
    'pt6sn8': {
        'name': 'è´Ÿè½½å‹ Pt6Sn8',
        'system_pattern': r'^pt6sn8',
        'output_subdir': 'step2.1.1_pt6sn8_msd',
        'output_prefix': 'pt6sn8_loaded',
        'title': r'Pt$_6$Sn$_8$ (Loaded)'
    },
    'cv': {
        'name': 'Pt6Sn8O4 (Cv)',
        'system_pattern': r'^Cv',
        'output_subdir': 'step2.1.1_cv_msd',
        'output_prefix': 'pt6sn8o4_cv',
        'title': r'Pt$_6$Sn$_8$O$_4$ (Cv)'
    }
}

# ===== é…ç½® =====
BASE_DIR = Path(__file__).parent
GMX_DATA_DIR = BASE_DIR / 'data' / 'gmx_msd' / 'unwrap' / 'gmx_msd_results_20251118_152614'

# æ ¹æ®é€‰æ‹©è®¾ç½®é…ç½®
current_config = DATASET_CONFIGS[DATASET]
OUTPUT_DIR = BASE_DIR / 'results' / current_config['output_subdir']
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

TARGET_SYSTEM = current_config['system_pattern']
TARGET_TEMPS = ['300K', '900K']
TARGET_ELEMENT = 'PtSn'  # åªç»˜åˆ¶æ•´ä½“ MSD

# ç»˜å›¾é…ç½®
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10

COLORS = {
    '300K': '#1E90FF',  # è“è‰²
    '900K': '#DC143C'   # çº¢è‰²
}


def load_outlier_list(csv_path, element='PtSn'):
    """
    åŠ è½½å¼‚å¸¸ run æ¸…å•
    
    Parameters:
    -----------
    csv_path : Path
        large_D_outliers.csv è·¯å¾„
    element : str
        ç›®æ ‡å…ƒç´  (Pt/Sn/PtSn)
    
    Returns:
    --------
    set : å¼‚å¸¸æ–‡ä»¶è·¯å¾„é›†åˆ (ä½¿ç”¨æ ‡å‡†åŒ–è·¯å¾„)
    """
    if not csv_path.exists():
        print(f"    âš ï¸ å¼‚å¸¸æ¸…å•ä¸å­˜åœ¨: {csv_path}")
        return set()
    
    try:
        df = pd.read_csv(csv_path)
        # ç­›é€‰ç›®æ ‡å…ƒç´ 
        df_elem = df[df['element'] == element]
        # æ ‡å‡†åŒ–è·¯å¾„ (ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ )
        outlier_paths = set()
        for fp in df_elem['filepath']:
            # æ ‡å‡†åŒ–è·¯å¾„ç”¨äºåŒ¹é…
            normalized = Path(fp).as_posix()
            outlier_paths.add(normalized)
        return outlier_paths
    except Exception as e:
        print(f"    âš ï¸ åŠ è½½å¼‚å¸¸æ¸…å•å¤±è´¥: {e}")
        return set()


def scan_msd_files(data_dir, system_pattern, temps, element, exclude_outliers=False):
    """
    æ‰«æ MSD æ•°æ®æ–‡ä»¶
    
    Returns:
    --------
    data_dict : dict
        {temperature: [file_path1, file_path2, ...]}
    """
    data_dir = Path(data_dir)
    data_dict = {temp: [] for temp in temps}
    
    # åŠ è½½å¼‚å¸¸æ¸…å•
    outlier_paths = set()
    if exclude_outliers and OUTLIER_CSV.exists():
        outlier_paths = load_outlier_list(OUTLIER_CSV, element)
        print(f"\n>>> åŠ è½½å¼‚å¸¸æ¸…å•: {len(outlier_paths)} ä¸ªå¼‚å¸¸ run")
    
    print(f"\n>>> æ‰«æ MSD æ•°æ®...")
    print(f"    ç›®å½•: {data_dir.name}")
    print(f"    ä½“ç³»: {system_pattern}")
    print(f"    å…ƒç´ : {element}")
    if exclude_outliers:
        print(f"    æ’é™¤å¼‚å¸¸: å·²å¯ç”¨")
    
    excluded_count = 0
    
    for xvg_file in data_dir.rglob(f"*_msd_{element}.xvg"):
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¼‚å¸¸æ¸…å•ä¸­
            if exclude_outliers and outlier_paths:
                file_posix = xvg_file.as_posix()
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ¹é…å¼‚å¸¸æ¸…å•
                is_outlier = False
                for outlier_path in outlier_paths:
                    # ä½¿ç”¨è·¯å¾„åç¼€åŒ¹é… (å› ä¸ºç»å¯¹è·¯å¾„å¯èƒ½ä¸åŒ)
                    if outlier_path.endswith(file_posix.split('gmx_msd_results_')[-1]) or \
                       file_posix.endswith(outlier_path.split('gmx_msd_results_')[-1]):
                        is_outlier = True
                        break
                if is_outlier:
                    excluded_count += 1
                    continue
            
            parts = xvg_file.parts
            
            # æå– temperature å’Œ composition
            temperature = None
            composition = None
            for i in range(len(parts)-1, 0, -1):
                if parts[i].endswith('K'):
                    temperature = parts[i]
                    composition = parts[i-1]
                    break
            
            if not temperature or not composition:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç›®æ ‡ä½“ç³»
            if not re.match(system_pattern, composition, re.IGNORECASE):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡æ¸©åº¦
            if temperature not in temps:
                continue
            
            data_dict[temperature].append(xvg_file)
            
        except Exception as e:
            continue
    
    for temp in temps:
        print(f"    {temp}: {len(data_dict[temp])} ä¸ªæ–‡ä»¶")
    
    if exclude_outliers and excluded_count > 0:
        print(f"    å·²æ’é™¤: {excluded_count} ä¸ªå¼‚å¸¸æ–‡ä»¶")
    
    return data_dict


def read_gmx_msd_xvg(filepath):
    """è¯»å– GMX MSD .xvg æ–‡ä»¶"""
    time_data = []
    msd_data = []
    
    try:
        with open(filepath, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#') or line.startswith('@'):
                    continue
                parts = line.split()
                if len(parts) >= 2:
                    try:
                        t = float(parts[0])  # ps
                        msd_nm2 = float(parts[1])
                        msd_a2 = msd_nm2 * 100  # nm^2 -> Ã…^2
                        time_data.append(t)
                        msd_data.append(msd_a2)
                    except ValueError:
                        continue
    except:
        return None, None
    
    if len(time_data) == 0:
        return None, None
    
    return np.array(time_data), np.array(msd_data)


def detect_outliers_iqr(values, multiplier=1.5):
    """
    ä½¿ç”¨ IQR æ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
    
    Parameters:
    -----------
    values : array-like
        æ•°æ®å€¼
    multiplier : float
        IQR å€æ•° (é»˜è®¤ 1.5)
    
    Returns:
    --------
    mask : ndarray
        True = æ­£å¸¸, False = å¼‚å¸¸
    """
    values = np.array(values)
    Q1 = np.percentile(values, 25)
    Q3 = np.percentile(values, 75)
    IQR = Q3 - Q1
    lower = Q1 - multiplier * IQR
    upper = Q3 + multiplier * IQR
    return (values >= lower) & (values <= upper)


def compute_ensemble_msd(file_list, apply_iqr_filter=True, iqr_multiplier=1.5):
    """
    è®¡ç®—ç³»ç»¼å¹³å‡ MSD
    
    Parameters:
    -----------
    file_list : list
        MSD æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    apply_iqr_filter : bool
        æ˜¯å¦åº”ç”¨ IQR å¼‚å¸¸è¿‡æ»¤
    iqr_multiplier : float
        IQR å€æ•°
    
    Returns:
    --------
    time : ndarray
        å…¬å…±æ—¶é—´è½´
    msd_mean : ndarray
        å¹³å‡ MSD
    msd_std : ndarray
        æ ‡å‡†å·®
    n_runs : int
        æœ‰æ•ˆè½¨è¿¹æ•°
    """
    all_msd = []
    all_time = []
    file_paths = []
    
    for filepath in file_list:
        time, msd = read_gmx_msd_xvg(filepath)
        if time is not None:
            all_time.append(time)
            all_msd.append(msd)
            file_paths.append(filepath)
    
    if not all_msd:
        return None, None, None, 0
    
    # æ‰¾å…¬å…±æ—¶é—´èŒƒå›´
    min_time = max(t.min() for t in all_time)
    max_time = min(t.max() for t in all_time)
    
    # åˆ›å»ºå…¬å…±æ—¶é—´è½´
    n_points = min(len(t) for t in all_time)
    common_time = np.linspace(min_time, max_time, n_points)
    
    # æ’å€¼åˆ°å…¬å…±æ—¶é—´è½´
    msd_interp = []
    for time, msd in zip(all_time, all_msd):
        msd_i = np.interp(common_time, time, msd)
        msd_interp.append(msd_i)
    
    msd_array = np.array(msd_interp)
    
    # ===== IQR å¼‚å¸¸è¿‡æ»¤ =====
    if apply_iqr_filter and len(msd_array) >= 3:
        # ä½¿ç”¨ MSD ç»ˆå€¼è¿›è¡Œå¼‚å¸¸æ£€æµ‹
        final_msd_values = msd_array[:, -1]
        normal_mask = detect_outliers_iqr(final_msd_values, iqr_multiplier)
        
        n_outliers = (~normal_mask).sum()
        if n_outliers > 0:
            # æ˜¾ç¤ºè¢«æ’é™¤çš„æ–‡ä»¶
            outlier_indices = np.where(~normal_mask)[0]
            print(f"    [IQRè¿‡æ»¤] æ’é™¤ {n_outliers} æ¡å¼‚å¸¸è½¨è¿¹:")
            for idx in outlier_indices:
                fp = file_paths[idx]
                # æå– Cv-x ç›®å½•å
                cv_match = re.search(r'(Cv-\d+)', str(fp))
                cv_name = cv_match.group(1) if cv_match else Path(fp).parent.parent.name
                print(f"      - {cv_name}: MSDç»ˆå€¼ = {final_msd_values[idx]:.2f} Ã…Â²")
            
            # åªä¿ç•™æ­£å¸¸æ•°æ®
            msd_array = msd_array[normal_mask]
    
    msd_mean = np.mean(msd_array, axis=0)
    msd_std = np.std(msd_array, axis=0, ddof=1) if len(msd_array) > 1 else np.zeros_like(msd_mean)
    
    return common_time, msd_mean, msd_std, len(msd_array)


def plot_msd_comparison(data_300k, data_900k, output_dir):
    """
    ç»˜åˆ¶ 300K vs 900K MSD å¯¹æ¯”å›¾
    """
    output_dir = Path(output_dir)
    
    # è®¡ç®—ç³»ç»¼å¹³å‡ (åº”ç”¨ IQR è¿‡æ»¤)
    print(f"\n>>> è®¡ç®—ç³»ç»¼å¹³å‡...")
    if APPLY_IQR_FILTER:
        print(f"    IQRè¿‡æ»¤: å·²å¯ç”¨ (multiplier={IQR_MULTIPLIER})")
    
    time_300, msd_300, std_300, n_300 = compute_ensemble_msd(
        data_300k, apply_iqr_filter=APPLY_IQR_FILTER, iqr_multiplier=IQR_MULTIPLIER)
    time_900, msd_900, std_900, n_900 = compute_ensemble_msd(
        data_900k, apply_iqr_filter=APPLY_IQR_FILTER, iqr_multiplier=IQR_MULTIPLIER)
    
    if time_300 is None or time_900 is None:
        print("  âš ï¸ æ•°æ®ä¸è¶³")
        return
    
    print(f"    300K: {n_300} æ¡è½¨è¿¹, MSDèŒƒå›´ [{msd_300.min():.2f}, {msd_300.max():.2f}] Ã…Â²")
    print(f"    900K: {n_900} æ¡è½¨è¿¹, MSDèŒƒå›´ [{msd_900.min():.2f}, {msd_900.max():.2f}] Ã…Â²")
    
    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(figsize=(10/2.54, 8/2.54))
    
    # ç»˜åˆ¶ 300K (è“è‰²)
    ax.fill_between(time_300, msd_300 - std_300, msd_300 + std_300,
                    alpha=0.3, color=COLORS['300K'])
    ax.plot(time_300, msd_300, color=COLORS['300K'], linewidth=1.5,
            label='300K')
    
    # ç»˜åˆ¶ 900K (çº¢è‰²)
    ax.fill_between(time_900, msd_900 - std_900, msd_900 + std_900,
                    alpha=0.3, color=COLORS['900K'])
    ax.plot(time_900, msd_900, color=COLORS['900K'], linewidth=1.5,
            label='900K')
    
    # æ ‡ç­¾å’Œæ ¼å¼
    ax.set_xlabel('Time (ps)', fontsize=10, fontweight='bold')
    ax.set_ylabel(r'MSD ($\AA^2$)', fontsize=10, fontweight='bold')
    
    # å›¾ä¾‹ - å°è€Œç´§å‡‘
    ax.legend(loc='upper left', fontsize=8, framealpha=0.8,
              handletextpad=0.3, borderpad=0.3, labelspacing=0.2)
    ax.tick_params(axis='both', which='major', labelsize=9)
    ax.set_xlim(0, max(time_300.max(), time_900.max()))
    ax.set_ylim(0, None)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    prefix = current_config['output_prefix']
    output_file = output_dir / f'{prefix}_msd_300K_vs_900K.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\nğŸ“Š å›¾ç‰‡å·²ä¿å­˜: {output_file}")
    
    # å¯¼å‡º CSV æ•°æ®
    export_msd_csv(time_300, msd_300, std_300, n_300,
                   time_900, msd_900, std_900, n_900, output_dir, prefix)
    
    return output_file


def export_msd_csv(time_300, msd_300, std_300, n_300,
                   time_900, msd_900, std_900, n_900, output_dir, prefix):
    """å¯¼å‡º MSD æ•°æ®åˆ° CSV"""
    output_dir = Path(output_dir)
    
    # å¯¼å‡º 300K æ•°æ®
    df_300 = pd.DataFrame({
        'Time_ps': time_300,
        'MSD_mean_A2': msd_300,
        'MSD_std_A2': std_300,
        'N_runs': n_300
    })
    csv_300 = output_dir / f'{prefix}_msd_300K.csv'
    df_300.to_csv(csv_300, index=False)
    print(f"    CSV: {csv_300}")
    
    # å¯¼å‡º 900K æ•°æ®
    df_900 = pd.DataFrame({
        'Time_ps': time_900,
        'MSD_mean_A2': msd_900,
        'MSD_std_A2': std_900,
        'N_runs': n_900
    })
    csv_900 = output_dir / f'{prefix}_msd_900K.csv'
    df_900.to_csv(csv_900, index=False)
    print(f"    CSV: {csv_900}")
    
    # å¯¼å‡ºç»Ÿè®¡æ±‡æ€»
    summary = pd.DataFrame({
        'Temperature': ['300K', '900K'],
        'N_runs': [n_300, n_900],
        'MSD_final_mean_A2': [msd_300[-1], msd_900[-1]],
        'MSD_final_std_A2': [std_300[-1], std_900[-1]],
        'MSD_max_A2': [msd_300.max(), msd_900.max()]
    })
    csv_summary = output_dir / f'{prefix}_msd_summary.csv'
    summary.to_csv(csv_summary, index=False)
    print(f"    æ±‡æ€»: {csv_summary}")
    
    # æ‰“å°ç»Ÿè®¡
    print(f"\n>>> MSD ç»Ÿè®¡æ±‡æ€»:")
    print(f"    {'Temperature':<12} {'N_runs':<8} {'MSD_final (Ã…Â²)':<20} {'MSD_max (Ã…Â²)':<15}")
    print(f"    {'-'*55}")
    print(f"    {'300K':<12} {n_300:<8} {msd_300[-1]:.2f} Â± {std_300[-1]:.2f} {'':<5} {msd_300.max():.2f}")
    print(f"    {'900K':<12} {n_900:<8} {msd_900[-1]:.2f} Â± {std_900[-1]:.2f} {'':<5} {msd_900.max():.2f}")
    print(f"    {'-'*55}")
    if msd_300[-1] > 0:
        print(f"    900K/300K æ¯”å€¼: {msd_900[-1]/msd_300[-1]:.1f}x")


def main():
    print(f"\n{'='*60}")
    dataset_name = current_config['name']
    print(f"Step 2.1.1: {dataset_name} MSD å¯¹æ¯” (300K vs 900K)")
    print(f"å½“å‰æ•°æ®é›†: {DATASET}")
    print(f"é¢„æ’é™¤å¼‚å¸¸(Step1): {'æ˜¯' if EXCLUDE_OUTLIERS else 'å¦'}")
    print(f"IQRå®æ—¶è¿‡æ»¤: {'æ˜¯ (x' + str(IQR_MULTIPLIER) + ')' if APPLY_IQR_FILTER else 'å¦'}")
    print(f"{'='*60}")
    
    # æ‰«ææ•°æ® (ä¼ å…¥æ’é™¤å¼€å…³)
    data_dict = scan_msd_files(GMX_DATA_DIR, TARGET_SYSTEM, TARGET_TEMPS, TARGET_ELEMENT, 
                                exclude_outliers=EXCLUDE_OUTLIERS)
    
    if not data_dict['300K'] or not data_dict['900K']:
        print(f"\n[X] é”™è¯¯: æ•°æ®ä¸è¶³")
        return
    
    # ç»˜å›¾
    print(f"\n>>> ç»˜åˆ¶ MSD å¯¹æ¯”å›¾...")
    plot_msd_comparison(data_dict['300K'], data_dict['900K'], OUTPUT_DIR)
    
    print(f"\n{'='*60}")
    print(f"âœ… å®Œæˆ!")
    print(f"{'='*60}")


if __name__ == '__main__':
    main()
